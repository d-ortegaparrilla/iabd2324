{"config":{"lang":["es"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"index.html","title":"Inicio","text":"<p>Apuntes creados para el curso de especializaci\u00f3n en Inteligencia Artificial y Big Data (IABD) impartido en el IES Severo Ochoa de Elche.</p> <p>El curriculum del curso de especializaci\u00f3n viene fijado por el Real Decreto 279/2021.</p>"},{"location":"index.html#indice-de-materiales","title":"\u00cdndice de materiales","text":"<ul> <li>Hola IA</li> <li>Aprendizaje supervisado</li> <li>MLOps</li> <li>Aprendizaje no supervisado</li> </ul>"},{"location":"aans/introduccion.html","title":"Introducci\u00f3n","text":"<p>La mayor\u00eda de las aplicaciones del machine learning se basan hoy en d\u00eda en el aprendizaje supervisado, la inmensa mayor\u00eda de los datos disponibles no est\u00e1 etiquetados.</p> <p>Las tareas m\u00e1s comunes del aprendizaje no supervisado son las siguientes:</p> <ul> <li>Reducci\u00f3n de la dimensionalidad. Utiliza distintas t\u00e9cnicas de extracci\u00f3n de caracter\u00edsticas para reducir el n\u00famero de caracter\u00edsticas de un conjunto de datos. Adem\u00e1s de acelerar el entrenamiento, la reducci\u00f3n de la dimensionalidad resulta muy \u00fatil para la visualizaci\u00f3n de datos.</li> <li>Clustering. Consiste en juntar instancias simulares en grupos. El agrupamiento es una herramienta estupenda para el an\u00e1lisis de datos, la segmentaci\u00f3n de mercado, los sistemas de recomendaci\u00f3n, los motores de b\u00fasqueda, la segmentaci\u00f3n de im\u00e1genes, el aprendizaje semisupervisado, la reducci\u00f3n de la dimensionalidad.</li> <li>Detecci\u00f3n de anomal\u00edas. El objetivo es aprender qu\u00e9 aspecto tienen los datos \"normales\" y, despu\u00e9s, utilizar eso para detectar instancias anormales. Estas instancias se llaman anomal\u00edas o valores at\u00edpicos, mientras que las instancias normales se llaman valores t\u00edpicos o inliers. La detecci\u00f3n de anomal\u00edas es \u00fatil para una gran variedad de aplicaciones, como la detecci\u00f3n de fraudes, la detecci\u00f3n de productos defectuosos en la fabricaci\u00f3n, la identificaci\u00f3n de tendencias nuevas en series temporales o la eliminaci\u00f3n de valores at\u00edpicos de un conjunto de datoas antes de entrenar otro modelo, lo cual puede mejorar de forma significativa el rendimiento del modelo resultante.</li> <li>Estimaci\u00f3n de densidad. Es la tarea de estimar la func\u00f3n de densidad de probabilidad del proceso aleatorio que ha generado el conjunto de datos. La estimaci\u00f3n de densidad se utiliza con frecuencia para la detecci\u00f3n de anomal\u00edas: es probable que las instancias ubicadas en regiones de densidad muy baja sean anomal\u00edas. Tambi\u00e9n resulta \u00fatil para la visualizaci\u00f3 y el an\u00e1lisis de datos.</li> </ul>"},{"location":"aans/anomalias/iforest.html","title":"Isolation Forest","text":"<p>Un Isolation Forest utiliza un conjunto de \u00e1rboles de decisi\u00f3n llamados \"\u00e1rboles de aislamiento\" para \"aislar\" las anomal\u00edas. Para entender c\u00f3mo funcionan, veamos un \u00e1rbol que comprueba si 5 es primo. En el nodo ra\u00edz preguntamos si cinco es divisible por dos. En caso afirmativo, no tenemos que verificar m\u00e1s. En caso negativo, seguimos haciendo preguntas de s\u00ed o no para los n\u00fameros inferiores a cinco. Los nodos en los que no se producen m\u00e1s ramificaciones o divisiones se denominan hojas. Este \u00e1rbol de decisi\u00f3n tiene tres niveles o una profundidad de tres. Cada vez que ocurre una nueva divisi\u00f3n, se agrega un nuevo nivel de profundidad al \u00e1rbol.</p> \u00c1rbol de decisi\u00f3n <p>Los \u00e1rboles de aislamiento, o iTrees, son versiones aleatorias de \u00e1rboles de decisi\u00f3n. En lugar de hacer preguntas espec\u00edficas, la divisi\u00f3n ocurre al azar. En otras palabras, para clasificar un punto de datos multidimensional en un valor interno o at\u00edpico, un iTree selecciona una caracter\u00edstica aleatoria del punto de datos y selecciona una divisi\u00f3n aleatoria entre los valores m\u00ednimo y m\u00e1ximo de esa caracter\u00edstica en cada nivel de profundidad. Dado que los valores at\u00edpicos dejan una gran \"brecha\" entre los valores internos, es m\u00e1s probable que la divisi\u00f3n aleatoria ocurra dentro de esa brecha, lo que resulta en el aislamiento de los valores at\u00edpicos al principio de la construcci\u00f3n del \u00e1rbol.</p> <p>Para ilustrar esto, veamos el ejemplo de la siguiente figura. Los puntos A a G son valores interiores, mientras que H e I son claramente valores at\u00edpicos.</p> Valores at\u00edpicos en 2D <p>Ajustemos un \u00fanico iTree a estos datos. En la primera divisi\u00f3n, seleccionamos aleatoriamente la caracter\u00edstica y elegimos aleatoriamente un valor de divisi\u00f3n de 1 punto 5. Esta \u00fanica divisi\u00f3n ya a\u00edsla a H como un valor at\u00edpico.</p> Isolation Tree <p>Otra divisi\u00f3n aleatoria para x con un valor de 1 punto 8 a\u00edsla a I como otro valor at\u00edpico.</p> Isolation Tree <p>Para aislar el resto, necesitamos m\u00e1s divisiones; aqu\u00ed hay cuatro m\u00e1s, que separan los puntos A, B, F y G. Para separar C, D, E, necesitar\u00edamos a\u00fan m\u00e1s divisiones.</p> Isolation Tree <p>Por lo tanto, los puntos que requieren menos divisiones o que est\u00e1n cerca del nodo ra\u00edz se convertir\u00e1n en valores at\u00edpicos. Un Isolation Forest utiliza una colecci\u00f3n de dichos iTrees y promedia sus resultados. El n\u00famero exacto de \u00e1rboles lo determinaremos nosotros.</p>"},{"location":"aans/anomalias/iforest.html#hiperparametros-de-un-isolation-forest","title":"Hiperpar\u00e1metros de un Isolation Forest","text":"<p>A continuaci\u00f3n veremos los hiperpar\u00e1metros m\u00e1s importantes de un Isolation Forest: contamination, n_estimators, max_samples y max_features.</p> <p>Despu\u00e9s del entrenamiento, IForest genera puntuaciones de anomal\u00edas sin procesar para cada punto de datos. En esta etapa, no sabemos cu\u00e1les son valores internos o at\u00edpicos. Para realizar la clasificaci\u00f3n, elegimos un umbral donde las puntuaciones de anomal\u00edas sin procesar se traducen en valores at\u00edpicos o at\u00edpicos. Este umbral se llama contaminaci\u00f3n. Por ejemplo, una contaminaci\u00f3n del 10 % significa que estamos eligiendo las observaciones con el 10 % superior de puntuaciones de anomal\u00eda como valores at\u00edpicos. Establecer la contaminaci\u00f3n correcta es fundamental para confiar en las predicciones de un algoritmo de detecci\u00f3n de valores at\u00edpicos multivariado. Una contaminaci\u00f3n baja da como resultado anomal\u00edas no detectadas, mientras que una contaminaci\u00f3n alta puede provocar que los valores internos se marquen como anomal\u00edas. La contaminaci\u00f3n no es un par\u00e1metro especial de algoritmo IForest, siendo usado en otros modelos de detecci\u00f3n de anomal\u00edas.</p> <p>Cuando queremos especificar el n\u00famero exacto de iTrees en IForest, usamos el par\u00e1metro n_estimators. El valor predeterminado es 100, que suele ser suficiente para conjuntos de datos peque\u00f1os. Usamos m\u00e1s \u00e1rboles para conjuntos de datos de alta dimensi\u00f3n para tener suficiente poder predictivo para aprender todos los patrones relevantes en los datos.</p> <p>Cada uno de estos \u00e1rboles se entrena en una submuestra del conjunto de datos y una submuestra de caracter\u00edsticas, controladas por los par\u00e1metros max_samples y max_features, que aceptan valores entre cero y uno. Por ejemplo, un IForest con 0.6 max_samples y 0.9 max_features entrena sus iTrees en el 60% de las filas y el 90% de las caracter\u00edsticas del conjunto de datos. Para cada iTree, se seleccionar\u00e1 un 60% diferente de las filas y un 90% diferente de las caracter\u00edsticas. Este submuestreo frecuente reduce el riesgo de sobreajuste.</p>"},{"location":"aans/anomalias/iforest.html#rendimiento-de-un-iforest","title":"Rendimiento de un iForest","text":"<p>Los algoritmos de aprendizaje supervisado se basan en m\u00e9tricas como RMSE para comprobar si los hiperpar\u00e1metros elegidos son efectivos. Los clasificadores de valores at\u00edpicos no pueden usar este tipo de m\u00e9tricas porque la detecci\u00f3n de valores at\u00edpicos es un problema de aprendizaje no supervisado. No tenemos etiquetas de valores internos/at\u00edpicos de antemano para medir la efectividad de los clasificadores de valores at\u00edpicos. No existe una manera f\u00e1cil de saber si una contaminaci\u00f3n del 7% es mejor que una contaminaci\u00f3n del 15% o si aumentar el n\u00famero de estimadores a mejores resultados. La \u00fanica forma de comprobar si el conjunto de hiperpar\u00e1metros elegido es efectivo es combinando el clasificador de valores at\u00edpicos con un modelo de aprendizaje supervisado y midiendo el rendimiento final con m\u00e9tricas como RMSE, p\u00e9rdida de registros o precisi\u00f3n. </p>"},{"location":"aans/anomalias/introduccion.html","title":"Introducci\u00f3n","text":"<p>La detecci\u00f3n de anomal\u00edas es un problema omnipresente en la ciencia de datos y el aprendizaje autom\u00e1tico, ya que la mayor\u00eda de los conjuntos de datos del mundo real tienen anomal\u00edas. La detecci\u00f3n de anomal\u00edas implica clasificar los datos en dos categor\u00edas: valores internos, o lo que consideramos puntos de datos normales, y valores at\u00edpicos, que son observaciones raras que difieren estad\u00edsticamente y parecen inconsistentes del resto de los datos.</p> <p>Estad\u00edsticamente hablando, un valor at\u00edpico es un punto de datos que tiene caracter\u00edsticas de diferencia anormales y estad\u00edsticamente significativas con respecto al resto de los datos. Hay que tener en cuenta que cualquiera que sea el m\u00e9todo utilizado para encontrar valores at\u00edpicos, la determinaci\u00f3n final de si un punto de datos es un valor at\u00edpico suele depender del observador.</p> <p>La detecci\u00f3n de anomal\u00edas tiene aplicaciones en muchas industrias:</p> <ul> <li>Seguridad inform\u00e1tica: b\u00fasqueda de brechas y ataques de seguridad.</li> <li>Medicina: detecci\u00f3n de tumores o c\u00e9lulas cancerosas.</li> <li>Finanzas y banca: detecci\u00f3n de fraudes.</li> </ul> <p>En es tipo de situaciones, se pueden utilizar t\u00e9cnicas de detecci\u00f3n de anomal\u00edas para investigar si los valores extremos afectan negativamente los an\u00e1lisis y modelos estad\u00edsticos.</p> <p>La media y la varianza son dos de las estad\u00edsticas resumidas m\u00e1s comunes, por lo que es importante apreciar c\u00f3mo pueden verse afectadas por los valores at\u00edpicos. El siguiente ejemplo muestra una serie de 10 n\u00fameros, donde 1289 puede identificarse claramente como un valor at\u00edpico.</p> <p>$$ 24, 46, 30, 28, 1289, 25, 21, 31, 48, 47 $$</p> <p>Si calculamos la media y varianzas con y sin el valor at\u00edpico obtenemos los siguientes resultados:</p> <p>Media (sin valor at\u00edpico) = 33.33</p> <p>Varianza (sin valor at\u00edpico) = 114.5</p> <p>Media = 158.9</p> <p>Varianza = 157771.65</p> <p>Los datos con el valor at\u00edpico mostrado tienen una media cinco veces mayor y una varianza casi 1400 veces mayor que los datos sin el valor at\u00edpico.</p> <p>Las anomal\u00edas tambi\u00e9n pueden generar ruido en los datos de entrenamiento. Los modelos de aprendizaje autom\u00e1tico pueden tratarlos como un subgrupo separado de los datos debido a su rareza y singularidad. Esto puede desviar la atenci\u00f3n de los patrones reales de los datos, lo que puede perjudicar el rendimiento del modelo.</p> <p>La detecci\u00f3n de valores at\u00edpicos no debe confundirse con la detecci\u00f3n de novedades. La detecci\u00f3n de valores at\u00edpicos encuentra valores at\u00edpicos s\u00f3lo en los datos de entrenamiento. Por el contrario, en la detecci\u00f3n de novedades, queremos saber si las observaciones en el conjunto de prueba tienen la misma distribuci\u00f3n que los datos con los que entrenamos. En otras palabras, las novedades s\u00f3lo existen en el conjunto de prueba. Si bien tanto la detecci\u00f3n de valores at\u00edpicos como la de novedades son parte de la detecci\u00f3n de anomal\u00edas, en este apartado nos centraremos en la detecci\u00f3n de valores at\u00edpicos.</p> <p>En el siguiente enlace puedes acceder a t\u00e9cnicas de detecci\u00f3n de valores at\u00edpicos mediante t\u00e9cnicas estad\u00edsticas. En este apartado trataremos distintos algoritmos de aprendizaje no supervisado para la detecci\u00f3n de valores at\u00edpicos multivariados, que son m\u00e1s comunes en los datos del mundo real que los valores at\u00edpicos univariados.Definimos valores at\u00edpicos multivariados como puntos de datos con dos o m\u00e1s atributos, que cuando se examinan individualmente no son necesariamente an\u00f3malos, pero son diferentes del resto cuando se consideran todos sus atributos al mismo tiempo.</p> <p>La siguiente figura muestra un ejemplo de valores at\u00edpicos multivariados.</p> Valor at\u00edpico multivariado <p>Estamos analizando datos de atenci\u00f3n m\u00e9dica recopilados de personas de 10 a 20 a\u00f1os y encontramos que un encuestado tiene 12 a\u00f1os, mide 160 cm de altura y pesa 190 libras. Cuando analizamos su edad, peso y altura individualmente, estos parecen estar dentro del rango de caracter\u00edsticas humanas t\u00edpicas. S\u00f3lo nos damos cuenta de que los ni\u00f1os de 12 a\u00f1os que miden 160 cm de altura no suelen pesar 190 libras cuando consideramos las tres caracter\u00edsticas simult\u00e1neamente. Este ni\u00f1o de 12 a\u00f1os en particular es un caso at\u00edpico en m\u00faltiples variables.</p>"},{"location":"aans/anomalias/lof.html","title":"Local Outlier Factor","text":"<p>El algoritmo valores at\u00edpicos locales (Local Outlier Factor, LOF) es un algoritmo popular basado en densidad. LOF funciona bien con conjuntos de datos de dimensiones moderadamente altas y es uno de los clasificadores de valores at\u00edpicos m\u00e1s r\u00e1pidos.</p> <p>LOF clasifica los puntos de datos en valores t\u00edpicos y at\u00edpicos utilizando una puntuaci\u00f3n de factor de valor at\u00edpico local. La puntuaci\u00f3n LOF se basa en el concepto de densidad local, donde la localidad se define eligiendo k vecinos m\u00e1s cercanos. La densidad misma se calcula entre un punto de datos y sus distancias a sus vecinos elegidos. Los puntos de datos con densidades similares formar\u00e1n un grupo, mientras que las muestras con densidades sustancialmente m\u00e1s bajas que su vecindario local se clasifican como valores at\u00edpicos.</p> <p>El concepto local es muy importante. La puntuaci\u00f3n LOF de una muestra no se compara con el resto del conjunto de datos, sino s\u00f3lo con su vecindad local.</p> <p>En la siguiente figura podemos ver un conjunto de datos normalizado bidimensional, con dos grupos de puntos de datos y una docena de valores at\u00edpicos. Los tama\u00f1os de los c\u00edrculos representan c\u00f3mo se comparan las muestras an\u00f3malas con su vecindario local. Cuanto mayor sea su puntuaci\u00f3n LOF, m\u00e1s grandes ser\u00e1n los c\u00edrculos. </p> Local Outlier Factor <p>El punto A es un valor at\u00edpico pero el tama\u00f1o del c\u00edrculo no es grande. Esto se debe a que est\u00e1 mucho m\u00e1s cerca de su vecindad local en comparaci\u00f3n con el punto B. El punto B est\u00e1 lejos y, por lo tanto, tiene mucha m\u00e1s desviaci\u00f3n y menos densidad, lo que hace que su c\u00edrculo sea m\u00e1s grande. Gracias a este enfoque local, LOF puede detectar valores at\u00edpicos que se habr\u00edan pasado por alto en otra \u00e1rea del conjunto de datos.</p>"},{"location":"aans/anomalias/lof.html#hiperparametros-de-loc","title":"Hiperpar\u00e1metros de LOC","text":"<p>El hiperpar\u00e1metro m\u00e1s importante de LOF es n_neighbors. Una buena pr\u00e1ctica es elegir 20 vecinos siempre que el n\u00famero de valores at\u00edpicos sea inferior al 10 % del n\u00famero total de instancias (contaminaci\u00f3n). Si hay m\u00e1s del 10%, n_vecinos debe aumentarse en consecuencia. </p> <p>Otro hiperpar\u00e1metro importante es p, que determina c\u00f3mo se calcula la distancia de una instancia respecto su vecindad. p = 2 es el valor por defecto y corresponde a la distancia eucl\u00eddea. p = 1 corresponder\u00eda a la distancia Manhattan. La distancia Minkowski permite generalizar p a otros valores, correspondi\u00e9ndose la form\u00fala a la que se muestra en la siguiente figura.</p> Distancia Minkowski"},{"location":"aans/anomalias/lof.html#rendimiento-de-lof","title":"Rendimiento de LOF","text":"<p>LOF usa una puntuaci\u00f3n de factor at\u00edpico local, que se calcula realizando c\u00e1lculos adicionales en la m\u00e9trica de distancia y usando conceptos como la distancia de accesibilidad local. Si bien las puntuaciones LOF alrededor de 1 generalmente denotan valores internos, no existe una regla clara sobre qu\u00e9 rango de valores representan valores at\u00edpicos. Estos valores dependen en gran medida del conjunto de datos.</p>"},{"location":"aans/clustering/dbscan.html","title":"Agrupamiento basado en regiones de alta densidad","text":"<p>El algoritmo DBSCAN (Density-Based Spatial Clustering of Applications with Noise) no hace suposiciones sobre cl\u00fasteres esf\u00e9ricos como k-means, ni particiona el conjunto de datos en jerarqu\u00edas. El clustering basado en dendidad asigna etiquetas de cl\u00fasteres basadas en regiones densas de puntos. En DBSCAN, la noci\u00f3n de densidad se define como el n\u00famero de puntos dentro de un radio determinado, $\\epsilon$.</p> <p>Seg\u00fan el algoritmo DBSCAN, se asigna una etiqueta especial a cada ejemplo (punto de datos) utilizando los siguientes criterios:</p> <ul> <li>Un punto se considera un punto central si al menos un n\u00famero determinado (MinPts) de puntos vecinos se encuentra dentro del radio especificado, $\\epsilon$.</li> <li>Un punto fronterizo es un punto que tiene menos vecinos que MinPts dentro de $\\epsilon$, pero que se encuentra dentro del radio $\\epsilon$ de un punto central.</li> <li>Todos los otros puntos que no son ni centrales ni fronterizos se consideran puntos de ruido.</li> </ul> <p>La siguiente figura muestra los distintos tipos de puntos:</p> Puntos centrales, fronterizos y de ruido <p>Tras etiquetar los puntos como centrales, de frontera o de ruido, el algoritmo DBSCAN puede resumirse en dos sencillos pasos:</p> <ol> <li>Forma un cl\u00faster separado para cada punto central o grupo conectado de puntos centrales. (Los puntos centrales est\u00e1n conectados si no est\u00e1n m\u00e1s lejos que $\\epsilon$.)</li> <li>Asigna cada punto fronterizo al cl\u00faster de su correspondiente punto central.</li> </ol>"},{"location":"aans/clustering/dbscan.html#comparativa-entre-algoritmos-de-clustering","title":"Comparativa entre algoritmos de clustering","text":"<p>Como se ha dicho anteriormente el algoritmo DBSCAN tiene un gran funcionamiento ante cl\u00fasters que no presentan una forma esf\u00e9rica. Esto se refleja en el siguiente conjunto de datos que presenta una forma de media luna.</p> Conjunto de datos en forma de media luna <p>La siguiente figura compara los cl\u00fasteres encontrados en dicho conjunto de datos mediante los algoritmos de clustering jer\u00e1rquico, k-means y DBSCAN. Como se puede observer el cl\u00faster encontrado por el algoritmo DBSCAN es m\u00e1s adecuado.</p> Clustering jer\u00e1rquico, k-means y DBSCAN en conjunto de datos en forma de media luna"},{"location":"aans/clustering/introduccion.html","title":"Introducci\u00f3n","text":"<p>El clustering o agrupamiento es la tarea de identificar instancias similares y asignarlas a grupos de instancias similares.</p> <p>Al igual que en la clasificaci\u00f3n, cada instancia se asigna a un grupo. Sin embargo, a diferencia de la clasificaci\u00f3n, el agrupamiento es una tarea no supervisado. </p> <p>La siguiente figura muestra a la izquierda el conjunto iri, donda la especie de cada instancia (es decir, su clase) se representa con un marcador diferente. Es un conjunto de datos etiquetado, para el que son adecuados algoritmos de clasificaci\u00f3n como clasificadores de regresi\u00f3n log\u00edstica, SVM o random forest. A la derecha, est\u00e1 el mismo conjunto de datos, pero sin las etiquetas, as\u00ed que ya no puedes utilizar un algoritmo de clasificaci\u00f3n. Aqu\u00ed es donde entran en acci\u00f3n los algoritmos de agrupamiento: muchos de ellos pueden detectar con facilidad el grupo inferior izquierdo. Tambi\u00e9n es bastante f\u00e1cil verlo con nuestros propios ojos, pero no es tan obvio que el grupo superior derecho est\u00e1 compuesto por dos subgrupos distintos. Dicho esto, el conjunto de datos tiene dos caracter\u00edsticas adicionales (longitud y anchura del s\u00e9palo) que no se representan aqu\u00ed, y los algoritmos de agrupamiento pueden aprovechar bien todas las caracter\u00edsticas, as\u00ed que, en realidad, identifican los tres grupos bastante bien.</p> Clasificaci\u00f3n (izquierda) frente a clustering (derecha)"},{"location":"aans/clustering/jerarquico.html","title":"Agrupamiento jer\u00e1rquico","text":"<p>Una de las ventajas del algoritmo de clustering jer\u00e1rquico es que nos permite representar dendrogramas (visualizaciones de un clustering jer\u00e1rquico binario), que pueden ayudar a la interpretaci\u00f3n de los resultados creando taxonom\u00edas coherentes. Otra ventaja es no necesitamos especificar el n\u00famero de cl\u00fasteres por adelantado.</p> <p>Los dos enfoques principales del clustering jer\u00e1rquico son el aglomerativo y el divisivo. En el clustering jer\u00e1rquico divisivo, comenzamos con un cl\u00faster que abarca todo el conjunto de datos, y lo dividimos iterativamente en cl\u00fasteres m\u00e1s peque\u00f1os, hasta que cada cl\u00faster solo contiene una instancia. Aqu\u00ed nos centraremos en el clustering aglomerativo, que adopta el enfoque opuesto. Comenzamos con cada instancia en un cl\u00faster individual y fusionamos los pares de cl\u00fasteres m\u00e1s cercanos hasta que solo queda un cl\u00faster.</p>"},{"location":"aans/clustering/jerarquico.html#agrupamiento-jerarquico-aglomerativo","title":"Agrupamiento jer\u00e1rquico aglomerativo","text":"<p>Los dos algoritmos est\u00e1ndar del clustering jer\u00e1rquico aglomerativo son el enlace sencillo y el enlace completo. En el caso del enlace sencillo, se calculan las distancias entre los miembros m\u00e1s similares de cada par de cl\u00fasteres y se fusionan los dos cl\u00fasteres cuya distancia entre los miembros m\u00e1s similares sea la menor. El enfoque de enlace completo es similar al del enlace sencillo, pero en lugar de comparar los miembros m\u00e1s similares de cada par de cl\u00fasteres, comparamos los miembros m\u00e1s dis\u00edmiles para realizar la fusi\u00f3n.</p> <p>La siguiente figura muestra la diferencia entre ambos tipo de enlaces:</p> Enlace sencillo y completo <p>Existen otros tipos de enlaces, como son el enlace promedio y el enlace de Ward. En el enlace promedio, se fusionan los pares de cl\u00fasteres bas\u00e1ndose en las distancias medias m\u00ednimas entre todos los miembros del grupo en los dos cl\u00fasteres. En el enlace de Ward, se fusionan los dos cl\u00fasteres que conducen al m\u00ednimo incremento de la inercia total en el cl\u00faster.</p> <p>El algoritmo de clustering aglomerativo utilizando un enfoque de enlace completo tendr\u00eda los siguientes pasos:</p> <ol> <li>C\u00e1lculo de la matriz de distancias por pares de todos los ejemplos.</li> <li>Representaci\u00f3n de cada punto de datos como un cl\u00faster \u00fanico.</li> <li>Fusi\u00f3n de los dos cl\u00fasteres m\u00e1s cercanos bas\u00e1ndose en la distancia entre los miembros m\u00e1s dis\u00edmiles (distantes).</li> <li>Actualizaci\u00f3n de la matriz de enlace de los cl\u00fasteres.</li> <li>Repetici\u00f3n de los pasos 2-4 hasta que quede un solo cl\u00faster.</li> </ol> <p>El dendrograma permite visualizar de forma gr\u00e1fica este proceso de creaci\u00f3n del cl\u00faster jer\u00e1rquico.</p> Dendrograma"},{"location":"aans/clustering/kmeans.html","title":"Agrupamiento basado en prototipos","text":""},{"location":"aans/clustering/kmeans.html#algoritmo-k-means","title":"Algoritmo k-means","text":"<p>En este apartado veremos uno de los algoritmos de clustering m\u00e1s populares, k-means. Este algoritmo permite encontrar grupos de objetos similares que est\u00e1n m\u00e1s relacionados entre s\u00ed que con los objetos de otros grupos.</p> <p>El algoritmo k-means es extraordinariamente f\u00e1cil de implementar, y tambi\u00e9n es computacionalmente muy eficiente en comparaci\u00f3n con otros algoritmos de clustering. Este algoritmo pertenece a la categor\u00eda de clustering basada en prototipos.</p> <p>El clustering basado en prototipos significa que cada cluster est\u00e1 representado bien por un prototipo que suele ser el centroide (media) de puntos similares. Aunque k-meas es muy bueno para identificar cl\u00fasteres con forma esf\u00e9rica, uno de los inconvenientes de este algoritmo de agrupamiento es que tenemos que especificar el n\u00famero de cl\u00fasteres, k, a priori. Una elecci\u00f3n inadecuada de k puede dar a un mal rendimiento del clustering.</p> <p>La siguiente figura muestra la representaci\u00f3n de un conjunto de ejemplos sin categorizar.</p> Conjunto de datos sin etiquetar <p>El algoritmo de k-means funciona de la siguiente manera:</p> <ol> <li>Elegir aleatoriamente k centroides de las instancias como centros de cl\u00fasteres iniciales.</li> <li>Asignar cada instancia al centroide m\u00e1s cercano.</li> <li>Mover los centroides al centro de las instancias que le fueron asignados.</li> <li>Repetir los pasos 2 y 3 hasta que las asignaciones de los cl\u00fasteres no cambien o se alcance una tolerancia definida por el usuario o se llegue a un n\u00famero m\u00e1ximo de iteraciones.</li> </ol> <p>La siguiente figura muestra el funcionamiento del algoritmo.</p> Algoritmo k-means <p>Existen variantes del algoritmo, como k-means++, la cual intenta situar los centroides iniciales lejos unos de otros. Esto conduce a resultados mejores y m\u00e1s consistentes que el cl\u00e1sico k-means.</p> <p>Es importante notar que es muy conveniente realizar un escalado de caracter\u00edsticas previo, para que todas estas se midan en la misma escala, normalizando o estandarizando las mismas.</p>"},{"location":"aans/clustering/kmeans.html#numero-optimo-de-clusteres","title":"N\u00famero \u00f3ptimo de cl\u00fasteres","text":"<p>Uno de los principales retos del aprendizaje no supervisado es que no conocemos las etiquetas de clase reales en nuestro conjunto de datos. Por ello, no podemos utilizar m\u00e9tricas de rendimiento como las que utilizamos en el aprendizaje supervisado.</p> <p>Para cuantificar la calidad del clustering, necesitamos utilizar m\u00e9tricas intr\u00ednsecas, como su inercia. La inercia es la suma de las distancias cuadr\u00e1ticas entre las instancias y sus centroides m\u00e1s pr\u00f3ximos. A mayor inercia peor calidad tendr\u00e1 el cl\u00faster.</p> <p>Podemos utilizar una herramienta gr\u00e1fica, el llamado m\u00e9todo del codo, para estimar el n\u00famero \u00f3ptimo de cl\u00fasteres, k, para una tarea determinada. Podemos decir que si k aumenta, la inercia disminuir\u00e1. La idea es identificar el valor de k en el que la reducci\u00f3n de la inercia comienza a reducir la velocidad de su disminuci\u00f3n.</p> <p>La siguiente figura muestra un ejemplo donde se determina que el codo toma un valor de k=4.</p> Detecci\u00f3n del valor \u00f3ptimo de k mediante la identificaci\u00f3n del codo <p>Existe otra m\u00e9trica llamada puntuaci\u00f3n de silueta que proporciona algo m\u00e1s de informaci\u00f3n que la inercia.</p> <p>Por ejemplo la siguiente figura, muestra para el anterior ejemplo, que aunque el valor de k=4 es \u00f3ptimo, un valor k=5 tambi\u00e9n dar\u00eda un cluster de buena calidad.</p> Detecci\u00f3n del valor \u00f3ptimo de k mediante la identificaci\u00f3n del codo <p>Los diagramas de silueta visualizan el coeficiente de silueta de cada instancia, ordenado por el grupo al que se asigna y por el valor de coeficiente. Cada diagrama contiene una forma de cuchillo por grupo. La altura de la forma indica el n\u00famero de instancias en el grupo y la anchura representa los coeficientes de silueta ordenados de las instancias en el grupo (cuanto m\u00e1s ancho, mejor). </p> <p>Las l\u00edneas discont\u00ednuas verticales representan la puntuaci\u00f3n media de la silueta para cada n\u00famero de grupos. Cuando la mayor\u00eda de las instancias de un grupo tienen un coeficiente m\u00e1s bajo que esta puntuaci\u00f3n (es decir, si muchas de las instancias terminan antes de llegar a la l\u00ednea discont\u00ednua y acaban a su izquierda), entonces el grupo es bastante malo, puesto que eso significa que sus instancias est\u00e1n demasiado cerca de otros grupos.</p> <p>La siguiente figura muestra el diagrama de silueta del anterior ejemplo.</p> Diagramas de silueta para distintos valores de k <p>En la anterior figura podemos ver que cuando k=3 o 6, obtenemos grupos bastante malos, pero, cuando k=4 o 5, los grupos est\u00e1n bastante bien: la mayor\u00eda de las instancias se extienden m\u00e1s all\u00e1 de la l\u00ednea discontinua, a la derecha y m\u00e1s cerca de 1.0. Cuando k=4, el grupo del \u00edndice 1 (el segundo empezando por abajo) es bastante grande. Cuando k=5, todos los grupos tienen tama\u00f1os similares. Por tanto, aunque la puntuaci\u00f3n de la silueta global de k=4 es un poco m\u00e1s grande que la de k=5, parece buena idea utilizar k=5 para obtener grupos de tama\u00f1os similares.</p>"},{"location":"aans/dimensionalidad/dimensionalidad.html","title":"Reducci\u00f3n de la dimensionalidad","text":"<p>Para una introducci\u00f3n al concepto de reducci\u00f3n de la dimensionalidad y de los procesos de selecci\u00f3n y extracci\u00f3n de caracter\u00edsticas, consultar el siguiente enlace.</p> <p>En los siguientes apartados entraremos en detalle con algunos de los enfoques principales para la reducci\u00f3n de la dimensionalidad: proyecci\u00f3n y aprendizaje de variedades.</p>"},{"location":"aans/dimensionalidad/proyeccion.html","title":"Proyecci\u00f3n","text":"<p>En la mayor\u00eda de problemas del mundo real, las instancias de entrenamiento no se extienden de manera uniforme a trav\u00e9s de todas las dimensiones. Muchas caracter\u00edsticas son casi constantes, mientras que otras est\u00e1n altamente correlacionadas. Como resultado, todas las instancias de entrenamiento quedan dentro (o cerca) de un subespacio con muchas menos dimensiones del espacio de alta dimensi\u00f3n.</p> <p>La siguiente figura muestra un conjunto de datos 3D representado por esferas peque\u00f1as.</p> Conjunto de datos 3D que queda cerca de un subespacio 2D <p>En la anterior figura todas las instancias de entrenamiento quedan cerca de un plano: se trata de un espacio con menos dimensiones (2D) del espacio de dimensiones m\u00e1s altas (3D). Si proyectamos cada instancia de entrenamiento perpendicularmente en este subespacio (como representan las l\u00edneas discontinuas cortas que conectan las instancias al plano), obtenemos el nuevo conjunto de datos 2D que se muestra en la siguiente figura. Los ejes corresponden a nuevas caracter\u00edsticas $ z_1 $ y $ z_2 $: son las coordenadas de las proyecciones en el plano.</p> Nuevo conjunto de datos 2D despu\u00e9s de la proyecci\u00f3n <p>A la derecha est\u00e1 el resultado de la proyecci\u00f3n del conjunto de datos en cada uno de estos ejes. Como puedes ver, la proyecci\u00f3n en la l\u00ednea cont\u00ednua se preserva la varianza m\u00e1xima (superior), mientras que la proyecci\u00f3n en la l\u00ednea de puntos preserva muy poca varianza (inferior) y la proyecci\u00f3n en la l\u00ednea discontinua preserva una cantidad intermedia de varianza (centro).</p> <p>De esta manera se selecciona el eje que preserva la m\u00e1xima cantidad de varianza, ya que lo m\u00e1s probable es que pierda menos informaci\u00f3n que las otras proyecciones. Otra manera de justificar esta elecci\u00f3n es que se trata del eje que minimiza la distancia cuadr\u00e1tica media entre el conjunto de datos original y su proyecci\u00f3n en ese eje.</p>"},{"location":"aans/dimensionalidad/proyeccion.html#pca","title":"PCA","text":"<p>El an\u00e1lisis de componentes principales (Principal Component Analysis, PCA) es, con diferencia, el algoritmo de reducci\u00f3n de dimensionalidad m\u00e1s popular. En primer lugar, identifica el hiperplano que queda m\u00e1s cerca de los datos y, a continuaci\u00f3n, proyecta en \u00e9l los datos.</p> <p>Antes de poder proyectar el conjunto de entrenamiento en un hiperplano con menos dimensiones, primero se tiene que elegir el hiperplano adecuado. Por ejemplo, en la parte izquierda de la siguiente figura se representa un conjunto de datos 2D simple, junto con tres ejes diferentes (es decir, hiperplanos 1D).</p> Nuevo conjunto de datos 2D despu\u00e9s de la proyecci\u00f3n"},{"location":"aans/dimensionalidad/variedades.html","title":"Aprendizaje de variedades","text":"<p>La proyecci\u00f3n no siempre es el mejor enfoque para la reducci\u00f3n de dimensionalidad. En muchos casos, el subespacio puede retorcerse, como en el conjunto de datos con la estructura Swiss roll (con forma de brazo de gitano) que se representa en la siguiente figura.</p> Conjunto de datos con la estructura Swiss roll <p>Proyectar en un plano sin m\u00e1s (por ejemplo, eliminando $ x_3 $) apretujar\u00eda diferentes capas del brazo de gitano, como se muesetra en el lado izquierdo de la siguiente figura. Es probable que lo que m\u00e1s convenga en este caso sea desenrollar el brazo de gitano para obtener el conjunto 2D del lado derecho de la figura.</p> Conjunto de datos con la estructura Swiss roll <p>La estructura Swiss roll es un ejemplo de variedad 2D. De manera simplificada, una variedad 2D es una forma 2D que puede doblarse y retorcerse en un espacio con m\u00e1s dimensiones. A nivel m\u00e1s general, una variedad de $ d $ dimensiones es una parte de un espacio de $ n $ dimensiones (donde $ d &lt; n $) que se parece a un hiperplano de $ d $ dimensiones a nivel local.</p> <p>Muchos algoritmos de reducci\u00f3n de dimensionalidad act\u00faan modelando la variedad en la que quedan las instancias de entrenamiento; esto se denomina aprendizaje de variedades. En muchas ocasiones la mayor\u00eda de conjuntos de datos de alta dimensi\u00f3n del mundo real quedan cerca de una variedad con muchas menos dimensiones.</p> <p>No siempre la tarea que tenemos que realizar (por ejemplo, clasificaci\u00f3n o regresi\u00f3n) es m\u00e1s simple si se expresa en un espacio con menos dimensiones. Por ejemplo, en la fila superior de la siguiente figura, la estructura Swiss roll se divide en dos clases: en el espacio 3D (a la izquierda), el l\u00edmite de decisi\u00f3n ser\u00eda bastante complejo, pero en el espacio de variedades desenrollado 2D (a la derecha), el l\u00edmite de decisi\u00f3n es una l\u00ednea recta.</p> Conjunto de datos con la estructura Swiss roll <p>En cambio en el ejemplo de la fila inferior, el l\u00edmite de decisi\u00f3n se ubica en $ x_1 = 5 $ . Este l\u00edmite de decisi\u00f3n parece muy simple en el espacio 3D original (un plano vertical), pero parece m\u00e1s complejo en la variedad desenrollada (una colecci\u00f3n de cuatro segmentos independientes).</p> <p>En resumen, reducir la dimensionalidad del conjunto de entrenamiento antes de entrenar el modelo suele acelerar el entrenamiento, pero puede que no siempre lleve a una soluci\u00f3n mejor o m\u00e1s simple; todo depende del conjunto de datos.</p>"},{"location":"aas/algoritmos/clasificacion.html","title":"Algoritmos de clasificaci\u00f3n","text":"<p>Una tarea de clasificaci\u00f3n se emplea para predecir una categor\u00eda, con un conjunto finito de valores posibles. En el caso de dos posibilidades se trata de clasificaci\u00f3n binaria; y si se quiere predecir m\u00e1s de dos categor\u00edas, se trata de clasificaci\u00f3n multiclase. </p> <p>La frontera de decisi\u00f3n (decision boundary) separa las diferentes clases predichas. Si un algoritmo clasificador aprende una frontera de decisi\u00f3n de tipo lineal, se dice que es un clasificador lineal (lineal classifier).</p> <p>Las siguientes im\u00e1genes muestra un clasificador lineal frente a un no lineal para una tarea de clasificaci\u00f3n binaria (2 clases), que utiliza 2 caracter\u00edsticas. </p> <p></p> <p>Existen clases en la que no es posible utilizar clasificadores lineales con \u00e9xito, ya que no son linealmente separables. La siguiente imagen ejemplifica esto:</p> <p></p> <p>En el caso del dataset Iris tenemos 3 categor\u00edas posibles, por lo que tendr\u00edamos un clasificador multiclase.</p> <p></p> <p>En los anteriores ejemplos se muestran clasificadores que utilizan 2 caracter\u00edsticas, lo que permite representarlos en un plano (ancho por alto). En estos las fronteras de decisi\u00f3n de los clasificadores lineales se visualizan como l\u00edneas rectas.  Esto se puede generalizar para clasificadores que utilicen m\u00e1s 2 caracter\u00edsticas. Con 5 caracter\u00edsticas, el espacio de valores de X es en 5 dimensiones. En este caso, la frontera de decisi\u00f3n ser\u00eda un hiperplano en 4 dimensiones que separar\u00eda el espacio en 2 mitades.</p> <p>La siguiente imagen muestra un clasificador binario con 3 caracter\u00edsticas:</p> <p></p> <p>A continuaci\u00f3n, se detallar\u00e1n algunos algoritmos de clasificaci\u00f3n.</p>"},{"location":"aas/algoritmos/clasificacion.html#k-vecinos-mas-proximos","title":"K vecinos m\u00e1s pr\u00f3ximos","text":"<p>El algoritmo de k vecinos m\u00e1s pr\u00f3ximos (k-nearest neighbors, k-NN), es un algoritmo supervisado basando en instancias, sin que sea necesario que haya una concordancia exacta con los datos del conjunto de entrenamiento, de forma que el algoritmo clasifica el nuevo elemento en el conjunto que le corresponde buscando en las observaciones m\u00e1s cercanas. Para ello, calcula las distancias a los elementos y las ordena de menor a mayor para asignar el grupo que tenga una frecuencia m\u00e1s alta con las distancias menores.</p> <p>Este m\u00e9todo es muy sensible al par\u00e1metro k, que indica el n\u00famero de vecinos seleccionado y la m\u00e9trica de distancia utilizada. El valor de k se fija tras realizar varias pruebas o mediante una validaci\u00f3n cruzada. La siguiente imagen muestra c\u00f3mo cambia la frontera de decisi\u00f3n conforme se cambia el par\u00e1metro k.</p> <p></p> <p>Como mayor inconveniente, este m\u00e9todo necesita todo el conjunto de datos de entrenamiento para cada elemento nuevo a clasificar, por lo que requiere gran cantidad de memoria y consumo de procesamiento. Por este motivo, es recomendable para conjuntos peque\u00f1os.</p>"},{"location":"aas/algoritmos/clasificacion.html#arboles-de-decision","title":"\u00c1rboles de decisi\u00f3n","text":"<p>Los \u00e1rboles de decisi\u00f3n (Decision Tree, DT) son algoritmos para hacer clasificaciones realizando particiones sucesivas, mediante la t\u00e9cnica denominada segmentaci\u00f3n jer\u00e1rquica, agrupando observaciones similares. Analizan situaciones que presentan varias posibilidades de decisi\u00f3n y toman la que consideran mejor.</p> <p>El m\u00e9todo, cuando se encuentra ante una decisi\u00f3n, utiliza la informaci\u00f3n del conjunto de datos de entrenamiento para buscar una correlaci\u00f3n entre el elemento nuevo y los conocidos y as\u00ed poder elegir la opci\u00f3n correcta.  Los \u00e1rboles de decisi\u00f3n est\u00e1n formados por los siguientes componentes:</p> <ul> <li>Nodos: son las variables de entrada y plantean las opciones de decisi\u00f3n, siendo el primer elemento del \u00e1rbol el nodo ra\u00edz.</li> <li>Ramas: indican los valores que pueden tomar las variables de entrada y unen los nodos entre s\u00ed.</li> <li>Hojas: muestran los valores de las variables de salida, es decir, el resultado de la decisi\u00f3n.</li> </ul> <p>Algunos de los algoritmos de \u00e1rboles de decisi\u00f3n m\u00e1s utilizados son los siguientes:</p> <ul> <li> <p>El algoritmo de \u00e1rboles de clasificaci\u00f3n y regresi\u00f3n (CART) genera \u00e1rboles de decisi\u00f3n binarios, por lo que cada nodo se divide en dos ramas.   </p> </li> <li> <p>Los algoritmos C5.0, que es una evoluci\u00f3n del C4.5 que a su vez los es de ID3, forman una familia de algoritmos de los m\u00e1s utilizados en tareas de clasificaci\u00f3n.</p> </li> <li>El algoritmo de bosque aleatorio (Random Forest, RF) combina varios \u00e1rboles con distinta cantidad k de caracter\u00edsticas y la salida de cada uno de ellos proporciona un voto, siendo la opci\u00f3n m\u00e1s votada la elegida como la respuesta del modelo.   </li> </ul> <p>Este m\u00e9todo no es apropiado para conjuntos de datos peque\u00f1os y requiere mucho tiempo durante la fase de entrenamiento.</p>"},{"location":"aas/algoritmos/clasificacion.html#algoritmo-clasificador-bayesiano-ingenuo","title":"Algoritmo clasificador bayesiano ingenuo","text":"<p>El algoritmo clasificador bayesiano ingenuo (Na\u00efve Bayes) es una t\u00e9cnica de clasificaci\u00f3n probabil\u00edstica que est\u00e1 fundamentada en el teorema de Bayes y est\u00e1 basada en la idea de que el mejor modelo es el m\u00e1s probable, asumiendo que la ocurrencia de una determinada caracter\u00edstica es independiente de que sucedan las otras particularidades. Este es el motivo por el que se le llama ingenuo.</p> <p>Solo requiere un peque\u00f1o conjunto de datos de entrenamiento para realizar la estimaci\u00f3n de los par\u00e1metros necesarios: medias y varianzas.</p> <p>Es un algoritmo simple y efectivo que se utiliza frecuentemente en la clasificaci\u00f3n de texto.</p>"},{"location":"aas/algoritmos/clasificacion.html#analisis-discriminante","title":"An\u00e1lisis discriminante","text":"<p>El an\u00e1lisis discriminante lineal (Lineal Discriminant Analysis, LDA) calcula unas funciones lineales a partir de los atributos de su perfil, donde la funci\u00f3n que alcanza mayor valor define el grupo al que pertenece el nuevo elemento de forma m\u00e1s probable. Cada elemento solamente puede pertenecer a un \u00fanico grupo. </p>"},{"location":"aas/algoritmos/clasificacion.html#regresion-logistica","title":"Regresi\u00f3n log\u00edstica","text":"<p>Asigna una probabilidad entre 0 y 1 de que una instancia pertenezca a una categor\u00eda. En el caso de una clasificaci\u00f3n binaria una instancia se clasificar\u00eda a una categor\u00eda cuando esta probabilidad sea &gt;= 0.5.</p> <p>Se representa mediante una curva formada con forma de S, llamada funci\u00f3n sigmoidea, que es una funci\u00f3n matem\u00e1tica que se utiliza para asignar los valores predichos a las probabilidades.</p> <p></p>"},{"location":"aas/algoritmos/clasificacion.html#maquinas-de-vector-soporte","title":"M\u00e1quinas de vector soporte","text":"<p>Las m\u00e1quinas de vector soporte (Support Vector Machines, SVM) separan un grupo dado de datos de entrenamiento etiquetados binarios mediante un hiperplano que est\u00e1 a una distancia m\u00e1xima de ellos (conocido como el hiperplano de margen m\u00e1ximo). De esta forma, elementos que son etiquetados con una categor\u00eda estar\u00e1n a un lado del hiperplano y los casos que se encuentren en la otra categor\u00eda se situar\u00e1n al otro lado. Al vector formado por los puntos m\u00e1s cercanos al hiperplano se le llama vector de soporte.</p> <p></p>"},{"location":"aas/algoritmos/introduccion.html","title":"Introducci\u00f3n","text":"<p>El aprendizaje autom\u00e1tico supervisado parte de un conjunto de datos de entrenamiento que est\u00e1n previamente etiquetados, en el cual se conoce el valor del atributo objetivo o respuesta. Esto hace que el algoritmo pueda aprender y obtener una funci\u00f3n que sea capaz de generalizar y predecir la respuesta para un conjunto de valores nuevo.</p> <p>Existen dos grandes grupos de m\u00e9todos supervisados: algoritmos de regresi\u00f3n y algoritmos de clasificaci\u00f3n.</p>"},{"location":"aas/algoritmos/regresion.html","title":"Algoritmos de regresi\u00f3n","text":"<p>Los modelos de regresi\u00f3n se utilizan para pronosticar variables objetivo en una escala continua, lo que los hace atractivos para abordar muchas cuestiones de la ciencia. Tambi\u00e9n tiene aplicaciones en la industria, como son la comprensi\u00f3n de las relaciones entre variables, la evaluaci\u00f3n de tendencias o la realizaci\u00f3n de previsiones. Un ejemplo es el pron\u00f3stico de las ventas de una empresa en los meses futuros.</p>"},{"location":"aas/algoritmos/regresion.html#regresion-lineal","title":"Regresi\u00f3n lineal","text":"<p>La regresi\u00f3n lineal simple (univariante) es modelar la relaci\u00f3n entre una \u00fanica caracter\u00edstica (variable explicativa, x) y un objetivo de valor continuo (variable de respuesta, y). La ecuaci\u00f3n de un modelo lineal con una sola variable explicativa se define como sigue: $$ y = w_1 x + b $$</p> <p>, siendo $ b $, la intersecci\u00f3n con el eje $ y $, y $ w_i $ el coeficiente de peso de la variable explicativa.</p> <p>Bas\u00e1ndonos en la ecuaci\u00f3n lineal que hemos definido anteriormente, la regresi\u00f3n lineal puede entenderse como la b\u00fasqueda de la l\u00ednea recta que mejor se ajusta a los ejemplos de entrenamiento.</p> <p></p> <p>Podemos generalizar el modelo de regresi\u00f3n lineal a m\u00faltiples variables explicativas, denomin\u00e1ndose este proceso regresi\u00f3n lineal m\u00faltiple. $$ y = w_1 x_1 + ... + w_m x_m + b $$</p> <p>A continuaci\u00f3n se muestra una imagen de una regresi\u00f3n lineal m\u00faltiple con 2 caracter\u00edstica y 1 valor objetivo.</p> <p></p>"},{"location":"aas/algoritmos/regresion.html#regresion-polinomica","title":"Regresi\u00f3n polin\u00f3mica","text":"<p>Se puede utilizar un modelo de regresi\u00f3n polin\u00f3mica a\u00f1adiendo t\u00e9rminos polin\u00f3micos: $$ y = w_1 x + w_2 x^2 + \u2026 + w_d x^d + b $$</p> <p>A continuaci\u00f3n se muestra una imagen de una regresi\u00f3n polin\u00f3mica simple con 1 caracter\u00edstica y 1 valor objetivo.</p> <p></p>"},{"location":"aas/algoritmos/regresion.html#uso-de-algoritmos-de-clasificacion-en-tareas-de-regresion","title":"Uso de algoritmos de clasificaci\u00f3n en tareas de regresi\u00f3n","text":"<p>Los algoritmos vistos en el apartado de clasificaci\u00f3n pueden utilizarse, con ligeras modificaciones, a algoritmos de regresi\u00f3n para la predicci\u00f3n de valores continuos, las m\u00e1quinas de vector de soporte aplicadas a la regresi\u00f3n (SVR), el m\u00e9todo de vecinos m\u00e1s cercanos (k-NN), \u00e1rboles de decisi\u00f3n (DTR) y bosques aleatorios (RFR).</p>"},{"location":"aas/ensamblaje/bagging.html","title":"Bagging y Pasting","text":"<p>Otro enfoque es utilizar el mismo algoritmo de entrenamiento para todos los predictores, pero entrenarlos en subconjuntos aleatorios distintos del conjunto de entrenamiento. Cuando se realiza un muestreo con reemplazo este m\u00e9todo se llama bagging. Cuando el muestreo se realiza sin reemplazo se denomina pasting. Un ejemplo de muestreo con reemplazo es cuando se coge una carta al azar de una baraja, la anotas y vuelves a ponerla en la baraha antes de coger la siguiente, por lo que podr\u00eda muestrearse la misma carta varias veces.</p> <p></p> <p>Dicho de otro modo, tanto el bagging como el pasting permiten entrenar instancias para que se muestreen varias veces a trav\u00e9s de m\u00faltiples predictores, pero solo el bagging permite entrenar instancias para que se muestreen varias veces para el mismo predictor.</p> <p>Como se puede observar en la siguiente imagen, todos los predictores pueden entrenarse en paralelo, mediante diferentes n\u00facleos de CPU o, incluso, en diferentes servidores. De manera similar, pueden hacerse predicciones en paralelo.</p> <p>Esta es una de las razones por lo que el bagging y el pasting son m\u00e9todos tan populares: escalan muy bien.</p> <p></p> <p>Cada predictor individual tiene un sesgo m\u00e1s alto que si se entrenase con el conjunto de datos individual, pero la agregaci\u00f3n reduce tanto el ses como la varianza. Por lo general, el resultado neto es que el ensamble tiene un sesgo similar, pero una varianza m\u00e1s baja que un solo predictor entrenado con el conjunto de datos original. La siguiente imagen ejemplifica este punto.</p> <p></p>"},{"location":"aas/ensamblaje/bagging.html#random-forests","title":"Random forests","text":"<p>Un random forest es un ensamble de \u00e1rboles de decisi\u00f3n, entrenado, por lo general, mediante el m\u00e9todo bagging.</p> <p>El algoritmo random forest introduce una aleatoriedad extra cuando hace crecer los \u00e1rboles; en vez de buscar la mejor caracter\u00edstica cuando divide un nodo, busca la mejor caracter\u00edstica entre un subconjunto aleatorio de caracter\u00edsticas. El algoritmo tiene como resultado una diversidad de \u00e1rboles mayor, lo cual compensa un sesgo m\u00e1s alto por una varianza m\u00e1s baja, produciendo, habitualmente un modelo mejor a nivel general.</p> <p>Asimismo, los random forests permiten medir la importancia relativa de cada caracter\u00edstica. Se mide dicha importancia fij\u00e1ndose en cu\u00e1nto reducen la impureza, de media, los nodos de \u00e1rboles que utilizan esa caracter\u00edstica, a trav\u00e9s de todos los \u00e1rboles del bosque.</p>"},{"location":"aas/ensamblaje/boosting.html","title":"Boosting","text":"<p>El boosting se refiere a cualquier m\u00e9todo de ensamblaje que pueda combinar varios aprendices d\u00e9biles para formar un aprendiz fuerte. La idea general de la mayor\u00eda de los m\u00e9todos de boosting es entrenar predictores de manera secuencial, de forma que cada uno de ellos intente corregir a su predecesor.</p> <p>Esta t\u00e9cnica de aprendizaje secuencial tiene un inconveniente importante: el entrenamiento no puede usarse en paralelo, puesto que cada predictor solo puede entrenarse despu\u00e9s que el predictor anterior se haya entrenado y evaluado. Como resultado no escala tan bien como el bagging o el pasting.</p> <p>Hay muchos m\u00e9todos de boosting pero los m\u00e1s populares son, con diferencia, AdaBoost y gradient boosting.</p>"},{"location":"aas/ensamblaje/boosting.html#adaboost","title":"AdaBoost","text":"<p>Una manera de que un predictor nuevo corrija a su predecesor es prestar un poco m\u00e1s de atenci\u00f3n a las instancias de entrenamiento que el predecesor subajusta. Esto da lugar a que los predictores nuevos se centren cada vez m\u00e1s en los casos dif\u00edciles.</p> <p>El algoritmo de AdaBoost entrena primero un clasificador base (por ejemplo, un \u00e1rbol de decisi\u00f3n) y lo utiliza para hacer predicciones en el conjunto de entrenamiento. Despu\u00e9s, el algoritmo incrementa el peso relativo de las instancias de entrenamiento mal clasificadas. A continuaci\u00f3n, entrena un segundo clasificador, utilizando los pesos actualizados y vuelve a hacer predicciones en el conjunto de entrenamiento, actualiza los pesos de las instancias, y as\u00ed sucesivamente.</p> <p></p> <p>La siguiente imagen muestra los l\u00edmites de decisi\u00f3n de cinco predictores consecutivos. El primer clasificador se equivoca con muchas instancias, as\u00ed que sus pesos se potencian. Por tanto, el segundo clasificador hace un trabajo un poco mejor con esas instancias, y as\u00ed sucesivamente. El gr\u00e1fico de la derecha representa la misma secuencia de predictores, pero la tasa de aprendizaje est\u00e1 dividida por la mitad (es decir, los pesos de instancias que se han clasificado mal se potencian mucho menos en cada iteraci\u00f3n).</p> <p></p> <p>Una vez que todos los predictores se han entrenado, el ensamble hace predicciones de manera muy similar al bagging o el pasting, salvo porque los predictores tienen diferentes pesos, dependiendo de su exactitud general en el conjunto de entrenamiento ponderado.</p>"},{"location":"aas/ensamblaje/boosting.html#gradient-boosting","title":"Gradient boosting","text":"<p>Al igual que AdaBoost, gradient boosting funciona a\u00f1adiendo predictores a un ensamble de manera secuencial, de modo que cada uno de ellos corrige a su predecesor. Sin embargo, en vez de ajustar la instancia en cada iteraci\u00f3n, como hace AdaBoost, este m\u00e9todo intenta ajustar el nuevo predictor a los errores residuales cometidos por el predictor anterior.</p> <p>La siguiente figura muestra un ejemplo que utiliza \u00e1rboles de decisi\u00f3n como predictores b\u00e1sicos. Las predicciones de estos tres \u00e1rboles se muestran en la columna izquierda y la predicci\u00f3n del ensamble en la derecha. En la primera fila, el ensamble tiene solo un \u00e1rbol, as\u00ed que las predicciones son exactamente las mismas que las del primer \u00e1rbol. En la segunda fila se entrena un \u00e1rbol nuevo con los errores residuales del primero. A la derecha se muestra que las predicciones del ensamble son iguales a la suma de las predicciones de los dos primeros \u00e1rboles. Del mismo modo, en la tercera fila, se entrena un \u00e1rbol con los errores residuales del segundo \u00e1rbol. Se puede observar que las predicciones del ensamble mejoran gradualmente a medida que a\u00f1adimos \u00e1rboles.</p> <p></p> <p>La siguiente figura muestra dos ensambles entrenados con hiperpar\u00e1metros diferentes: el de la izquierda no tiene suficientes \u00e1rboles para ajustar el conjunto de entrenamiento, mientras que el de la derecha tiene la cantidad adecuada. Si a\u00f1adi\u00e9semos m\u00e1s \u00e1rboles, el ensamble empezar\u00eda a sobreajustar el conjunto de entrenamiento.</p> <p></p>"},{"location":"aas/ensamblaje/introduccion.html","title":"Introducci\u00f3n","text":"<p>Si se suman las predicciones de un grupo de predictores (como clasificadores o regresores), a menudo se obtendr\u00e1n predicciones mejores que con el mejor predictor individual. Un grupo de predictores se denomina ensamble. Esta t\u00e9cnica se conoce como ensamblaje y un algoritmo de ensamblaje se llama m\u00e9todo de ensamblaje.</p> <p>Un ejemplo de m\u00e9todo de ensamblaje puede ser un grupo de \u00e1rboles de decisi\u00f3n, cada uno en un subconjunto aleatorio del conjunto de entrenamiento diferente. Posteriormente se obtienen las predicciones de todos los \u00e1rboles individuales y la clase que consigue m\u00e1s votos es la predicci\u00f3n del ensamble.</p> <p>A menudo se usan los m\u00e9todos de ensamblaje cerca del final de un proyecto, para combinarlos y formar un predictor a\u00fan mejor.</p>"},{"location":"aas/ensamblaje/votacion.html","title":"M\u00e9todos por votaci\u00f3n","text":"<p>Supongamos que hemos entrenado varios clasificadores y cada uno ha conseguido una exactitud de alrededor del 80%. Podr\u00edamos tener un clasificador de regresi\u00f3n log\u00edstica, un clasificador SVM, un clasificador random forest, un clasificador de k vecinos m\u00e1s cercanos y quiz\u00e1s algunos m\u00e1s.</p> <p></p> <p>Una manera muy sencilla de crear un clasificador a\u00fan mejor es sumar las predicciones de los clasificadores: la clase que obtiene m\u00e1s votos es la predicci\u00f3n del ensamble. Este clasificador por voto de la mayor\u00eda se llama clasificador hard voting.</p> <p></p> <p>De manera un tanto sorprendente, este clasificador de votaci\u00f3n consigue, a menudo, una exactitud mayor que el mejor clasificador del ensamble. De hecho, incluso aunque un clasificador sea un aprendiz d\u00e9bil (lo que significa que el resultado es solo un poco mejor que una suposici\u00f3n aleatoria), el ensamble puede ser un aprendiz fuerte (consiguiendo una exactitud elevada), siempre y cuando haya un n\u00famero suficiente de aprendices d\u00e9biles en el ensamble y estos sean lo bastante diversos.</p> <p>Los m\u00e9todos de ensamblaje funcionan mejor cuando los predictores son tan independientes unos respecto a otros como sea posible. Una manera de conseguir clasificadores diversos es entrenarlos utilizando algoritmos muy distintos. Eso incrementa las posibilidades de que cometan tipos de errores muy diferentes, lo que mejora la exactitud del ensamble.</p> <p>Si todos los clasificadores son capaces de estimar las probabilidades de clase, se puede establecer que se prediga la clase con la probabilidad de clase m\u00e1s alta, promediada sobre todos los clasificadores individuales. Esto se denomina soft voting. A menudo, consigue un rendimiento m\u00e1s alto que el hard voting porque da m\u00e1s peso a los votos que son m\u00e1s seguros.</p> <p>Todo esto se puede aplicar de manera an\u00e1loga a problemas de regresi\u00f3n. Para ello el ensamble utilizar\u00e1 el promedio obtenido por cada uno de los predictores, para calcular el valor final de la regresi\u00f3n.</p>"},{"location":"aas/hiperparametros/curvas.html","title":"Curvas de aprendizaje y validaci\u00f3n","text":"<p>Las curvas de aprendizaje y de validaci\u00f3n son dos herramientas de diagn\u00f3stico muy sencillas pero potentes, que pueden ayudarnos a mejorar el rendimiento de los algoritmos de aprendizaje.</p> <p>Las curvas de aprendizaje nos ayudar\u00e1n a diagnosticar si un algoritmo de aprendizaje tiene un problema de sobreajuste. En estos casos se dice tambi\u00e9n que el algoritmo presenta una alta varianza (variance). Tambi\u00e9n nos permitir\u00e1 detectar casos de subajuste, donde se dice que el algoritmo presenta un alto sesgo (bias).</p> <p>Las curvas de validaci\u00f3n nos ayudar\u00e1n a resolver problemas habituales de los algoritmos de aprendizaje.</p>"},{"location":"aas/hiperparametros/curvas.html#diagnostico-de-problemas-de-sesgo-y-varianza-con-curvas-de-aprendizaje","title":"Diagn\u00f3stico de problemas de sesgo y varianza con curvas de aprendizaje","text":"<p>Si un modelo es demasiado complejo para un conjunto de datos de entrenamiento determinado (por ejemplo un \u00e1rbol de decisi\u00f3n muy profundo), el modelo tiende a sobreajustarse a los datos de entrenamiento y no generaliza bien los datos no vistos. A menudo, puede ser \u00fatil recoger m\u00e1s ejemplos de entrenamiento para reducir el grado de sobreajuste.</p> <p>Sin embargo, en la pr\u00e1ctica, esto puede ser muy caro o, simplemente, puede no ser factible recoger m\u00e1s datos. Al representar las precisiones de entrenamiento y validaci\u00f3n del modelo en funci\u00f3n del tama\u00f1o del conjunto de datos de entrenamiento, podemos detectar f\u00e1cilmente si el modelo sufre una alta varianza o un alto sesgo, y si la recogida de m\u00e1s datos podr\u00eda ayudar a resolver este problema.</p> <p></p> <p>La anterior figura muestra en la parte superior izquierda un modelo con un alto sesgo. Este modelo tiene una exactitud baja tanto en el entrenamiento como en la validaci\u00f3n cruzada, lo que indica que no se ajusta a los datos de entrenamiento. Las formas habituales de abordar este problema son aumentar el n\u00famero de car\u00e1cteristicas del modelo (por ejemplo, recopilando o construyendo caracter\u00edsticas adicionales) o disminuir el grado de regularizaci\u00f3n (mediante el ajuste de un hiperpar\u00e1metro).</p> <p>En la parte superior derecha de la figura se muestra un modelo que sufre una alta varianza, lo que se indica por la gran diferencia entre la exactitud de entrenamiento y la de validaci\u00f3n cruzada. Para solucionar este problema de sobreajuste, podemos recoger m\u00e1s datos de entrenamiento, reducir la complejidad del modelo o aumentar el grado regularizaci\u00f3n. Para los modelos no regularizados puede ser \u00fatil reducir el n\u00famero de caracter\u00edsticas.</p>"},{"location":"aas/hiperparametros/curvas.html#diagnistico-de-problemas-de-sesgo-y-varianza-con-curvas-de-validacion","title":"Diagn\u00edstico de problemas de sesgo y varianza con curvas de validaci\u00f3n","text":"<p>Las curvas de validaci\u00f3n son una herramienta \u00fatil para mejorar el rendimiento de un modelo al abordar cuestiones sobre el sobreajuste o el subajuste. Est\u00e1n relacionadas con las curvas de aprendizaje, pero en lugar de representar las exactitudes de entrenamiento y prueba en funci\u00f3n del tama\u00f1o de la muestra, variamos los valores de los hiperpar\u00e1metros del modelo.</p>"},{"location":"aas/hiperparametros/introduccion.html","title":"Introducci\u00f3n","text":"<p>En el aprendizaje autom\u00e1tico, tenemos dos tipos de par\u00e1metros: los par\u00e1metros que se aprenden de los datos de entrenamiento (por ejemplo, los pesos en una regresi\u00f3n log\u00edstica) y los par\u00e1metros del algoritmo de aprendizaje que se optimizan por separado, tambi\u00e9n llamados par\u00e1metros de ajuste o hiperpar\u00e1metros del modelo (por ejemplo el par\u00e1metro de regularizaci\u00f3n en la regresi\u00f3n log\u00edstica o el par\u00e1metro de profundidad m\u00e1xima de un \u00e1rbol de decisi\u00f3n).</p> <p>En esta secci\u00f3n utilizaremos distintas t\u00e9cnicas que nos permitir\u00e1n ajustar estos hiperpar\u00e1metros con el objetivo de optimizar el rendimiento de nuestros modelos.</p>"},{"location":"aas/hiperparametros/red.html","title":"B\u00fasqueda en la red","text":"<p>La b\u00fasqueda en red, al igual que las curvas de validaci\u00f3n, permiten mejorar el rendimiento del modelo ajustando sus hiperpar\u00e1metros.</p> <p>Estudiaremos dos m\u00e9todos de b\u00fasqueda en red: el m\u00e9todo de b\u00fasqueda en cuadr\u00edcula y el de b\u00fasqueda aleatoria.</p> <p>El enfoque de b\u00fasqueda en cuadr\u00edcula se trata de un paradigma de b\u00fasqueda exhaustiva por fuerza bruta, en el que especificamos una lista de valores para diferentes hiperpar\u00e1metros, y el ordenador eval\u00faa el rendimiento del modelo para cada combinaci\u00f3n para obtener la combinaci\u00f3n \u00f3ptima de valores de este conjunto.</p> <p>Dado que la b\u00fasqueda en cuadr\u00edcula es una b\u00fasqueda exhaustiva, garantiza que encontrar\u00e1 la configuraci\u00f3n \u00f3ptima de hiperpar\u00e1metros si est\u00e1 contenida en la cuadr\u00edcula de par\u00e1metros especificada por el usuario. Sin embargo, la especificaci\u00f3n de grandes cuadr\u00edculas de hiperpar\u00e1metros hace que la b\u00fasqueda en cuadr\u00edcula, en la pr\u00e1ctica, sea muy costosa. Un enfoque alternativo para el muestreo de diferentes combinaciones de par\u00e1metros es la b\u00fasqueda aleatoria.</p> <p>En la b\u00fasqueda aleatoria, extraemos al azar configuraciones de hiperpar\u00e1metros de distribuciones. A diferencia de la b\u00fasqueda en cuadr\u00edcula, la b\u00fasqueda aleatoria no realiza una b\u00fasqueda exhaustiva en el espacio de hiperpar\u00e1metros. Sin embargo, nos permite explorar una gama m\u00e1s amplia de configuraciones de valores de hiperpar\u00e1metros de una manera m\u00e1s eficaz en cuanto a costes y tiempo.</p> <p>La siguiente figura muestra una cuadr\u00edcula determinada de nueve ajustes de hiperpar\u00e1metros que se buscan mediante los m\u00e9todos de b\u00fasqueda en cuadr\u00edcula y b\u00fasqueda aleatoria.</p> <p></p>"},{"location":"aas/particion/crossvalidation.html","title":"Validaci\u00f3n cruzada con k grupos","text":"<p>Una desventaja del m\u00e9todo de retenci\u00f3n es que la estimaci\u00f3n del rendimiento puede ser muy sensible a la forma en que dividimos el conjunto de datos de entrenamiento en subconjuntos de entrenamiento y de validaci\u00f3n; la estimaci\u00f3n variar\u00e1 para diferentes ejemplos de los datos. </p> <p>En la validaci\u00f3n cruzada con k grupos k-fold cross validation dividimos aleatoriamente el conjunto de datos de entrenamiento en k grupos sin sustituci\u00f3n. En este caso, se utilizan k -1 grupos, llamados grupos de entrenamiento, para el entrenamiento del modelo, y un grupo, llamado grupo de prueba, para la evaluaci\u00f3n del rendimiento. Este procedimiento se repite k veces, de modo que se obtienen k modelos y estimaciones de rendimiento.</p> <p>A continuaci\u00f3n, calculamos el rendimiento medio de los modelos bas\u00e1ndonos en las diferentes iteraciones de prueba independientes para obtener una estimaci\u00f3n del rendimiento que sea menos sensible a la subpartici\u00f3n de los datos de entrenamiento en comparaci\u00f3n con el m\u00e9todo de retenci\u00f3n. Normalmente, utilizamos la validaci\u00f3n cruzada para el ajuste del modelo, es decir, para encontrar los valores \u00f3ptims de los hiperpar\u00e1metros que producen un rendimiento de generalizaci\u00f3n satisfactorio.</p> <p></p> <p>Una vez que hayamos encontrado valores satisfactorios de los hiperpar\u00e1metros, podemos volver a entrenar el modelo con el conjunto de datos de entrenamiento completo y obtener una estimaci\u00f3n final del rendimiento utilizando el conjunto de datos de prueba independiente. La raz\u00f3n para ajustar un modelo a todo el conjunto de datos de entrenamiento despu\u00e9s de la validaci\u00f3n cruzada es que, en primer lugar, normalmente estamos interesados en un \u00fanico modelo final, al que tras proporcionarle m\u00e1s ejemplos de entrenamiento, tendr\u00e1 como resultado un modelo m\u00e1s preciso y robusto.</p>"},{"location":"aas/particion/crossvalidation.html#validacion-cruzada-dejando-uno-fuera","title":"Validaci\u00f3n cruzada dejando uno fuera","text":"<p>Un caso especial de validaci\u00f3n cruzada de k grupos es el m\u00e9todo de validaci\u00f3n cruzada dejando uno fuera (Leave One Out Cross Validation, LOOCV).</p> <p>En LOOCV se hace que el n\u00famero de iteraciones sea igual al n\u00famero de ejemplos de entrenamiento (k = n), para que solo se utilice un ejemplo de entrenamiento para las pruebas durante cada iteraci\u00f3n. Es un enfoque recomendado para trabajar con conjunto de datos muy peque\u00f1os.</p>"},{"location":"aas/particion/crossvalidation.html#validacion-cruzada-estratificada","title":"Validaci\u00f3n cruzada estratificada","text":"<p>En la validaci\u00f3n cruzada estratificada, las proporciones de las etiquetas de clase se conservan en cada subconjunto para garantizar que cada subconjunto sea representativo de las proporciones de clase en el conjunto de entrenamiento. Este enfoque puede producir mejores estimaciones, especialmente en casos de proporciones de clase desiguales.</p>"},{"location":"aas/particion/introduccion.html","title":"Introducci\u00f3n","text":"<p>En anteriores apartados se ha explicado c\u00f3mo separar nuestro conjunto de datos en 2 partes diferenciadas: un conjunto de entrenamiento para entrenar nuestro modelo y un conjunto de prueba para evaluar dicho modelo.</p> <p>En este apartado iremos m\u00e1s all\u00e1 explicando las t\u00e9cnicas habituales de retenci\u00f3n, validaci\u00f3n cruzada, que pueden ayudarnos a obtener estimaciones fiables del rendimiento de generalizaci\u00f3n del modelo, es decir, lo bien que se comporta el modelo con datos no vistos.</p>"},{"location":"aas/particion/retencion.html","title":"M\u00e9todo de retenci\u00f3n","text":"<p>Un enfoque cl\u00e1sico y muy utilizado para estimar el rendimiento de generalizaci\u00f3n de los modelos de aprendizaje autom\u00e1tico es el m\u00e9todo de retenci\u00f3n. En este m\u00e9todo dividimos nuestro conjunto de datos inicial en conjunto de datos de entrenamiento y de prueba separados: el primero se utiliza para el entrenamiento del modelo y el segundo se utiliza para estimar su rendimiento de generalizaci\u00f3n.</p> <p></p> <p>Sin embargo, en las aplicaciones t\u00edpicas de aprendizaje autom\u00e1tico, tambi\u00e9n nos interesa ajustar y comparar diferentes configuraciones de par\u00e1metros para mejorar a\u00fan m\u00e1s el rendimiento a la hora de realizar pron\u00f3sticos sobre datos no vistos. Este proceso se denomina selecci\u00f3n del modelo, y hace referencia a un problema de clasificaci\u00f3n determinado para el que queremos seleccionar los valores \u00f3ptimos de los par\u00e1metros de ajuste, tambi\u00e9n llamados hiperpar\u00e1metros.</p> <p>Por desgracia, si reutilizamos el mismo conjunto de datos de prueba una y otra vez durante la selecci\u00f3n del modelo, se convertir\u00e1 en parte de nuestros datos de entrenamiento y, por tanto, ser\u00e1 m\u00e1s probable que el modelo se sobreajuste. A pesar de este problema, mucha gente sigue utilizando el conjunto de datos de prueba para la selecci\u00f3n del modelo, pero no es una buena pr\u00e1ctica de aprendizaje autom\u00e1tico.</p> <p>Una forma m\u00e1s conveniente de utilizar el m\u00e9todo de retenci\u00f3n para la selecci\u00f3n del modelo es separar los datos en tres partes: un conjunto de datos de entrenamiento, un conjunto de datos de validaci\u00f3n y un conjunto de datos de prueba. El conjunto de datos de entrenamiento se utiliza para ajustar los diferentes modelos, y el rendimiento del conjunto de datos de validaci\u00f3n se utiliza para la selecci\u00f3n del modelo. </p> <p></p> <p>La ventaja de contar con un conjunto de datos de prueba que el modelo no ha visto antes durante los pasos de entrenamiento y selecci\u00f3n del modelo es que podemos obtener una estimaci\u00f3n menos sesgada de su capacidad de generalizaci\u00f3n a los nuevos datos.</p>"},{"location":"aas/validacion/introduccion.html","title":"Introducci\u00f3n","text":"<p>La validaci\u00f3n de un modelo consta de varios pasos y procesos que garantizan que un modelo funciona como se espera cuando recibe nuevos datos. La forma m\u00e1s com\u00fan de hacer esto es probar la precisi\u00f3n de un modelo en datos que nunca antes hab\u00eda visto (llamado conjunto de prueba). Si la precisi\u00f3n del modelo es similar para los datos con los que se entren\u00f3 y para los datos de prueba, se puede afirmar que el modelo est\u00e1 validado. Sin embargo, la validaci\u00f3n del modelo tambi\u00e9n puede consistir en elegir el modelo correcto, los mejores par\u00e1metros e incluso la mejor m\u00e9trica de precisi\u00f3n. El objetivo final de la validaci\u00f3n de modelos es obtener el modelo con el mejor rendimiento posible, que logre una alta precisi\u00f3n en los datos nuevos. </p>"},{"location":"aas/validacion/introduccion.html#sobreajuste","title":"Sobreajuste","text":"<p>Normalmente, los modelos funcionan mucho mejor con datos que han visto antes, ya que los datos no vistos pueden tener rasgos o caracter\u00edsticas que no fueron expuestas en el modelo. Si los errores de entrenamiento y prueba son muy diferentes, puede ser una se\u00f1al de que el modelo est\u00e1 sobreajustado (overfitting). Usaremos la validaci\u00f3n del modelo para asegurarnos de obtener el mejor error de prueba posible.</p> <p>El sobreajuste ocurre cuando nuestro modelo comienza a darle significado al ruido en los datos de entrenamiento. En el siguiente gr\u00e1fico, se puede ver la forma cuadr\u00e1tica natural de los puntos naranjas. Sin embargo, la l\u00ednea de predicci\u00f3n azul se ajusta demasiado a los datos y probablemente no se extender\u00eda bien a nuevos puntos naranjas. </p> <p></p>"},{"location":"aas/validacion/introduccion.html#subajuste","title":"Subajuste","text":"<p>Si, por el contrario, obtenemos unos errores altos, tanto de entrenamiento como de prueba, puede ser que estemos ante un caso en el que el modelo no ha conseguido encontrar los patrones de relaci\u00f3n entre los datos. En este caso nuestro modelo estar\u00eda subajustado (underfitting).</p> <p>El subajuste ocurre cuando el modelo no pudo encontrar los patrones subyacentes disponibles en los datos. Esto podr\u00eda suceder si no tenemos nuestro modelo subyacente no tiene la suficiente complejidad. La siguiente imagen muestra un ejemplo de modelo subajustado para el conjunto de datos anterior.</p> <p></p>"},{"location":"aas/validacion/met_clasificacion.html","title":"M\u00e9tricas para modelos de clasificaci\u00f3n","text":"<p>Las m\u00e9tricas de precisi\u00f3n de la clasificaci\u00f3n son bastante diferentes a las de regresi\u00f3n. Como se ha comentado anteriormente, los modelos de clasificaci\u00f3n predicen en qu\u00e9 categor\u00eda cae una observaci\u00f3n. Hay muchas m\u00e9tricas de precisi\u00f3n disponibles: precisi\u00f3n, sensibilidad, exactitud, puntuaci\u00f3n F1, etc.</p> <p>Nos centraremos en la precisi\u00f3n, la recuperaci\u00f3n y la exactitud. Ya que cada uno de estos es f\u00e1cil de entender y tiene aplicaciones muy pr\u00e1cticas. Una forma de calcular estas m\u00e9tricas es utilizar los valores de una matriz de confusi\u00f3n.</p>"},{"location":"aas/validacion/met_clasificacion.html#matriz-de-confusion","title":"Matriz de confusi\u00f3n","text":"<p>Al hacer predicciones, especialmente si la clasificaci\u00f3n es binaria, la matriz de confusi\u00f3n (confusion matrix) es uno de los resultados m\u00e1s \u00fatiles a revisar en primera instancia. Cuando tenemos un resultado binario, la matriz de confusi\u00f3n es una matriz de 2x2 que muestra c\u00f3mo se ajustaron las predicciones en los dos resultados. Por ejemplo, para predicciones de 0 que en realidad fueron 0 (o verdaderos negativos), observamos la posici\u00f3n [0, 0] de la matriz. Todas las m\u00e9tricas de precisi\u00f3n mencionados anterioremente se pueden calcular utilizando los valores de esta matriz y es una excelente manera de visualizar los resultados iniciales de un modelo de clasificaci\u00f3n.</p> <p>La siguiente imagen muestra un ejemplo de una matriz de confusi\u00f3n para una clasificaci\u00f3n binaria.</p> <p></p>"},{"location":"aas/validacion/met_clasificacion.html#exactitud","title":"Exactitud","text":"<p>La exactitud (accuracy) es la m\u00e9trica m\u00e1s f\u00e1cil de entender y representa la capacidad general de un modelo para predecir correctamente la clasificaci\u00f3n correcta. Usando la matriz de confusi\u00f3n, se suman los valores que se predijeron como 0 y que en realidad son 0 (verdaderos negativos), a los valores que se predice que son 1 y que son 1 (verdaderos positivos), y luego dividimos por el n\u00famero total de observaciones. En el ejemplo anterior, la exactitud es del 85%.</p> <p></p>"},{"location":"aas/validacion/met_clasificacion.html#precision","title":"Precisi\u00f3n","text":"<p>La precisi\u00f3n (precision) es el n\u00famero de verdaderos positivos entre todos los valores positivos predichos. En el ejemplo anterior se predijeron correctamente 62 valores verdaderos pero tambi\u00e9n se predijo 7 falsos positivos. Por tanto, la precisi\u00f3n es 62 dividido por 69. La precisi\u00f3n se utiliza cuando no queremos sobrepredecir valores positivos. Si el coste de traer en avi\u00f3n a nuevos empleados potenciales es muy elevado, es posible que una empresa solo tenga entrevistas con personas que realmente creen que se unir\u00e1n a su empresa. En los datos del ejemplo, casi 9 de cada 10 predichos se habr\u00edan unido a la empresa.</p> <p></p>"},{"location":"aas/validacion/met_clasificacion.html#sensibilidad","title":"Sensibilidad","text":"<p>La sensibilidad (recall) consiste en encontrar todos los valores positivos. En el anterior ejemplo se predijo correctamente 62 verdaderos positivos y se tuvo 8 falsos negativos. La sensibilidad es de 62 entre 70. La sensibilidad se utiliza cuando no podemos darnos el lujo de perder ning\u00fan valor positivo. Por ejemplo, incluso si un paciente tiene una peque\u00f1a probabilidad de tener c\u00e1ncer, es posible que queramos realizarle pruebas adicionales. El coste de pasar por alto a un paciente que tiene c\u00e1ncer es mucho mayor que el costo de ex\u00e1menes de detecci\u00f3n adicionales para ese paciente.</p> <p></p>"},{"location":"aas/validacion/met_regresion.html","title":"M\u00e9tricas para modelos de regresi\u00f3n","text":"<p>Los modelos de regresi\u00f3n se construyen para variables continuas. </p>"},{"location":"aas/validacion/met_regresion.html#error-absoluto-medio-mae","title":"Error absoluto medio (MAE)","text":"<p>Para evaluar el desempe\u00f1o de un modelo de regresi\u00f3n, podemos utilizar el error absoluto medio (Mean Absolute Error, MAE). Es la m\u00e9trica de error m\u00e1s simple e intuitiva y es la diferencia absoluta promedio entre las predicciones $ y_i $ y los valores reales $ \\hat{y_i} $. </p> <p>$$ MAE = {\\sum_{i=1}^n \\lvert y_i - \\hat{y}_i \\rvert \\over n} $$</p> <p>Si un perro tuviera seis cachorros, pero hubieras predicho solo cuatro, la diferencia absoluta ser\u00eda dos. Esta m\u00e9trica trata todos los puntos por igual y no es sensible a los valores at\u00edpicos. Cuando se trata de aplicaciones en las que no queremos que los errores grandes tengan un impacto importante, se puede utilizar el error absoluto medio. Un ejemplo podr\u00eda ser predecir la factura mensual de gasolina de un autom\u00f3vil, cuando un valor at\u00edpico puede haber sido causado por un \u00fanico viaje por carretera.</p>"},{"location":"aas/validacion/met_regresion.html#error-cuadratico-medio-mse","title":"Error cuadr\u00e1tico medio (MSE)","text":"<p>El siguiente es el error cuadr\u00e1tico medio (Mean Squared Error, MSE). Es la m\u00e9trica de error de regresi\u00f3n m\u00e1s utilizada para modelos de regresi\u00f3n. Se calcula de manera similar al error absoluto medio, pero esta vez elevamos al cuadrado el t\u00e9rmino de diferencia. </p> <p>$$ MSE = {\\sum_{i=1}^n (y_i - \\hat{y}_i)^2 \\over n} $$</p> <p>El MSE permite que errores mayores tengan un mayor impacto en el modelo. Utilizando el ejemplo anterior del autom\u00f3vil, si se supiera que una vez al a\u00f1o puede realizar un viaje por carretera, se puedea esperar tener de vez en cuando un error grande y se desee que el modelo se recupere de esos viajes.</p> <p>Tambi\u00e9n se suele utilizar la ra\u00edz cuadrada del error cuadr\u00e1tico medio, (Root Mean Squared Error, RMSE).</p> <p>$$ RMSE = \\sqrt{MSE} $$</p>"},{"location":"aas/validacion/met_regresion.html#r-cuadrado","title":"R cuadrado","text":"<p>R cuadrado (R-squared) es una m\u00e9trica que cuantifica la cantidad de varianza en la variable objetivo que se explica por las caracter\u00edsticas. Los valores pueden variar entre 0 y 1, donde uno significa que las caracter\u00edsticas explican completamente la variaci\u00f3n del objetivo. A continuaci\u00f3n hay dos gr\u00e1ficos que visualizan el R cuadrado alto y bajo respectivamente:</p> <p></p>"},{"location":"ia/fases_aa/entrenamiento.html","title":"Entrenamiento y selecci\u00f3n de modelos","text":"<p>Se han desarrollado muchos algoritmos diferentes de aprendizaje autom\u00e1tico para resolver tareas de distintas problem\u00e1ticas. Por ejemplo, cada algoritmo de clasificaci\u00f3n tiene sus sesgos inherentes, y ning\u00fan modelo de clasificaci\u00f3n goza de superioridad si no hacemos ninguna suposici\u00f3n sobre la tarea. En la pr\u00e1ctica, por tanto, es esencial comparar al menos un pu\u00f1ado de algoritmos de aprendizaje diferentes para entrenar, y seleccionar el modelo que mejor funcione. Pero, antes de poder comparar diferentes modelos, tenemos que decidir una m\u00e9trica para medir el rendimiento. Una m\u00e9trica com\u00fanmente utilizada es la precisi\u00f3n de la clasificaci\u00f3n, que se define como la proporci\u00f3n de instancias clasificadas correctamente.</p> <p>\u00bfC\u00f3mo sabemos qu\u00e9 modelo tiene un buen rendimiento con el conjunto de datos de prueba final y con los del mundo real si no utilizamos este conjunto de datos prueba para la selecci\u00f3n del modelo, sino que lo conservamos para la evaluaci\u00f3n final? Para abordar la cuesti\u00f3n que encierra esta pregunta, se pueden utilizar diferentes t\u00e9cnicas, que se resumen en la \u201cvalidaci\u00f3n cruzada\u201d. En la validaci\u00f3n cruzada, dividimos un conjunto de datos en subconjuntos de entrenamiento y validaci\u00f3n para estimar el rendimiento de generalizaci\u00f3n del modelo.</p> <p>Por \u00faltimo, tampoco podemos esperar que los par\u00e1metros por defecto de los diferentes algoritmos de aprendizaje proporcionados por las bibliotecas de software sean \u00f3ptimos para el problema espec\u00edfico de la tarea. Por lo tanto, ser\u00e1 necesario usar con frecuencias t\u00e9cnicas de optimizaci\u00f3n de hiperpar\u00e1metros que nos ayuden a ajustar el rendimiento de nuestro modelo.</p> <p>Podemos pensar en estos hiperpar\u00e1metros como par\u00e1metros que no se deducen de los datos, sino que representan los mandos del modelo sobre los que podemos actuar para mejorar su rendimiento.</p>"},{"location":"ia/fases_aa/evaluacion.html","title":"Evaluaci\u00f3n de modelos y pron\u00f3stico de instancias de datos ocultos","text":"<p>Despu\u00e9s de seleccionar un modelo que se ha ajustado con el conjunto de datos de entrenamiento, podemos utilizar el conjunto de datos de prueba para estimar su rendimiento con estos datos no vistos, para estimar el llamado error de generalizaci\u00f3n. Si estamos satisfechos con su rendimiento, podemos utilizar este modelo para pronosticar nuevos datos futuros. Es importante tener en cuenta que los par\u00e1metros de los procedimientos mencionados anteriormente, como el escalado de caracter\u00edsticas y la reducci\u00f3n de la dimensionalidad, se obtienen \u00fanicamente a partir del conjunto de datos de entrenamiento, y los mismos par\u00e1metros se vuelven a aplicar posteriormente para transformar el conjunto de datos de prueba, as\u00ed como cualquier instancia de datos nuevos, de lo contrario, el rendimiento medido en los datos de prueba podr\u00eda ser demasiado optimista. </p>"},{"location":"ia/fases_aa/introduccion.html","title":"Introducci\u00f3n","text":"<p>La siguiente figura muestra un flujo de trabajo t\u00edpico para un sistema de aprendizaje autom\u00e1tico. Esta figura nos servir\u00e1 de ayuda para detallar las distintas fases necesarias en este tipo de sistema cara a crear finalmente un modelo predictivo.</p> <p></p>"},{"location":"ia/fases_aa/preprocesamiento.html","title":"Preprocesamiento: c\u00f3mo dar forma a los datos","text":"<p>Los datos en bruto rara vez se presentan en la forma y el formato necesarios para el rendimiento \u00f3ptimo de un algoritmo de aprendizaje. Por ello, el preprocesamiento de los datos es uno de los pasos m\u00e1s importantes en cualquier aplicaci\u00f3n de aprendizaje autom\u00e1tico.</p> <p>El dataset Iris es un ejemplo cl\u00e1sico en el campo de aprendizaje autom\u00e1tico (se puede encontrar m\u00e1s informaci\u00f3n en https://archive.ics.uci.edu/dataset/53/iris. El dataset Iris contiene las medidas de 150 flores de iris de tres especies diferentes: setosa, versicolor y virginica. Aqu\u00ed, cada ejemplo de flor representa una fila en nuestro conjunto de datos, y las medidas de la flor en cent\u00edmetros se almacenan en columnas, a las que tambi\u00e9n llamaremos \u201ccaracter\u00edsticas del dataset\u201d.</p> <p></p> <p>Si tomamos como ejemplo el conjunto de datos de las flores Iris, podemos pensar en los datos brutos como una serie de im\u00e1genes de flores de las queremos extraer caracter\u00edsticas significativas. Las caracter\u00edsticas \u00fatiles podr\u00edan centrarse en el color de las flores, o en su altura, su longitud o su anchura.</p> <p>Muchos algoritmos de aprendizaje autom\u00e1tico tambi\u00e9n requieren, para un rendimiento \u00f3ptimo, que las caracter\u00edsticas seleccionadas est\u00e9n en la misma escala, lo que a menudo se consigue transformando las caracter\u00edsticas en el rango [0, 1], o en una distribuci\u00f3n normal est\u00e1ndar con media cero y varianza unitaria.</p> <p>Algunas de las caracter\u00edsticas seleccionadas pueden estar muy correlacionadas y, por tanto, ser redundantes hasta cierto punto. En estos casos, las t\u00e9cnicas de reducci\u00f3n de la dimensionalidad son \u00fatiles para comprimir las caracter\u00edsticas en un subespacio de menor dimensi\u00f3n. La reducci\u00f3n de la dimensionalidad de este espacio de caracter\u00edsticas tiene la ventaja de que se necesita menos espacio de almacenamiento y el algoritmo de aprendizaje puede funcionar mucho m\u00e1s r\u00e1pido. En ciertos casos, la reducci\u00f3n de la dimensionalidad puede mejorar el rendimiento predictivo de un modelo si el conjunto de datos contiene un gran n\u00famero de caracter\u00edsticas irrelevantes (o ruido); es decir, si el conjunto de datos tiene una baja relaci\u00f3n se\u00f1al-ruido.</p> <p>Para determinar si nuestro algoritmo de aprendizaje autom\u00e1tico no solo funciona bien con el conjunto de datos de entrenamiento, sino que tambi\u00e9n se generaliza bien a nuevos datos, tendremos que dividir aleatoriamente el conjunto de datos en conjunto de datos de entrenamiento y de prueba separados. Utilizamos el conjunto de entrenamiento para entrenar y optimizar nuestro modelo de aprendizaje autom\u00e1tico, y reservamos el conjunto de datos de prueba hasta el final para evaluar el modelo definitivo.</p>"},{"location":"ia/introduccion/campos.html","title":"Campos de aplicaci\u00f3n de la inteligencia de artificial.","text":"<p>A continuaci\u00f3n, vamos a entrar en detalle en los distintos campos de aplicaci\u00f3n de la inteligencia artificial.</p>"},{"location":"ia/introduccion/campos.html#vision-artificial","title":"Visi\u00f3n artificial","text":"<p>La visi\u00f3n artificial ha experimentado una transformaci\u00f3n radical gracias al aprendizaje profundo y las redes convolucionales en la \u00faltima d\u00e9cada. Estos avances han dado lugar a una amplia gama de aplicaciones, que van desde la clasificaci\u00f3n de im\u00e1genes hasta la identificaci\u00f3n de rostros, pasando por la detecci\u00f3n de objetos y el seguimiento de movimientos.</p> <p>En el \u00e1mbito de la clasificaci\u00f3n de im\u00e1genes, se han desarrollado algoritmos que pueden distinguir y categorizar objetos en fotograf\u00edas, como reconocer la diferencia entre perros y gatos o interpretar los n\u00fameros en las matr\u00edculas de los veh\u00edculos.</p> <p>Los algoritmos de seguimiento han permitido que drones equipados con c\u00e1maras realicen b\u00fasquedas y rastreos de personas desaparecidas, y sigan a posibles delincuentes. Combinados con c\u00e1maras t\u00e9rmicas, estos algoritmos se han convertido en herramientas de seguridad esenciales, utilizadas para supervisar \u00e1reas naturales y bosques con el objetivo de prevenir incendios.</p> <p>En el \u00e1mbito de la seguridad, los detectores de objetos se utilizan en sistemas de inspecci\u00f3n para evitar la introducci\u00f3n de armas u objetos prohibidos en trenes y aviones.</p> <p>Los segmentadores de im\u00e1genes permiten aislar objetos del fondo en una imagen, y esta tecnolog\u00eda se emplea con \u00e9xito en la construcci\u00f3n de modelos tridimensionales de \u00f3rganos a partir de im\u00e1genes m\u00e9dicas bidimensionales.</p> <p>Los identificadores de rostros, una forma especializada de los detectores de caras, posibilitan la creaci\u00f3n de sistemas avanzados de control de acceso. Un ejemplo destacado es un ascensor desarrollado por la empresa asturiana \"ATI Ascensores\" que puede identificar autom\u00e1ticamente a los residentes y llevarlos a su destino, lo que representa un avance importante para las personas con discapacidades motoras o sensoriales.</p> <p>Las redes generativas antag\u00f3nicas (Generative Adversarial Networks, GAN) han causado un impacto revolucionario en la industria cinematogr\u00e1fica, permitiendo la creaci\u00f3n de rostros extremadamente realistas de personas reales, incluso despu\u00e9s de su fallecimiento. Sin embargo, tambi\u00e9n han dado lugar a la proliferaci\u00f3n del software DeepFake, que puede modificar caras en im\u00e1genes y videos para hacer parecer que una persona es otra, inundando las tiendas de aplicaciones de dispositivos m\u00f3viles con estas herramientas.</p> <p>Adem\u00e1s, los autoencoders se utilizan para mejorar la calidad de las fotograf\u00edas y videos, eliminando el ruido y restaurando la claridad de las im\u00e1genes.</p>"},{"location":"ia/introduccion/campos.html#proceso-y-adquision-de-video","title":"Proceso y adquisi\u00f3n de v\u00eddeo","text":"<p>Al igual que en el anterior apartado, el procesamiento de videos (secuencias de im\u00e1genes en movimiento) y la representaci\u00f3n de escenas mediante t\u00e9cnicas como el trazado de rayos, el superescalado, DLSS y otros algoritmos de mejora han marcado un nuevo est\u00e1ndar en la industria de los videojuegos. Esto ha llevado la calidad de la gran pantalla directamente al hogar, aunque es importante tener en cuenta que los requisitos de hardware para lograrlo no deben subestimarse. Por ejemplo, para llevar a cabo estas tareas en videojuegos con resoluci\u00f3n Full HD o 2K (dependiendo del t\u00edtulo), se requiere una tarjeta gr\u00e1fica potente y moderna, como una RTX3060 de la familia Ampere o equivalente.</p> <p>El trazado de rayos (Ray Tracing) utiliza algoritmos avanzados que permiten determinar los lugares donde la luz se refleja o refracta para representar de manera precisa los reflejos y refracciones en tiempo real. En la d\u00e9cada de 2000, esta t\u00e9cnica se usaba principalmente para generar gr\u00e1ficos est\u00e1ticos como apoyo a la venta, por ejemplo, para renderizar im\u00e1genes de proyectos urban\u00edsticos complejos. Esto se hac\u00eda utilizando m\u00faltiples tarjetas gr\u00e1ficas en paralelo a trav\u00e9s de tecnolog\u00edas como SLI (Scalable Link Interface) o CrossFire.</p> <p>El superescalado (Supersampling) en t\u00e9rminos sencillos implica mejorar artificialmente una imagen para obtener una mayor resoluci\u00f3n en una pantalla, como una pantalla 4K, sin sacrificar la velocidad de cuadros por segundo (fps) generada por la tarjeta gr\u00e1fica. Existen diversas tecnolog\u00edas para lograrlo, siendo la m\u00e1s establecida la de NVIDIA con su Deep Learning Super Sampling (DLSS), seguida de cerca por AMD con FidelityFX Super Resolution (FSR).</p> <p>Adem\u00e1s, cabe mencionar DeepStream, que aunque no est\u00e1 directamente relacionado con las tecnolog\u00edas mencionadas anteriormente, consiste en un conjunto de bibliotecas de procesamiento de video que se est\u00e1 implementando en aplicaciones industriales para el control, an\u00e1lisis y procesamiento de videos, as\u00ed como datos de sensores \u00f3pticos.</p>"},{"location":"ia/introduccion/campos.html#reconocimiento-de-voz-y-lenguaje-natural","title":"Reconocimiento de voz y lenguaje natural.","text":"<p>Estas dos disciplinas est\u00e1n estrechamente relacionadas entre s\u00ed, al punto que varios expertos consideran el reconocimiento autom\u00e1tico del habla (ASR, Automatic Speech Recognition) como una subdisciplina del procesamiento de lenguaje natural (NLP, Natural Language Processing).</p> <p>El reconocimiento de voz y el procesamiento de lenguaje natural permiten buscar informaci\u00f3n espec\u00edfica, realizar traducciones autom\u00e1ticas y ofrecer una interfaz amigable para asistentes virtuales y chatbots.</p> <p>Los productos rob\u00f3ticos basados en la plataforma NVIDIA Jetson pueden aprovechar algoritmos de inteligencia artificial tanto en unidades de procesamiento gr\u00e1fico (GPU) como en unidades de procesamiento central (CPU) para llevar a cabo tareas de reconocimiento de voz y NLP. Es importante se\u00f1alar que el uso de NLP no siempre implica la utilizaci\u00f3n de inteligencia artificial, como se puede ver al emplear la Software Development Kit (SDK) de NLTK (Natural Language Tool Kit). En el caso de las tecnolog\u00edas propietarias de NVIDIA, NeMo y Jarvis son las interfaces de programaci\u00f3n de aplicaciones (API) encargadas de estas tareas, e incluso incluyen un motor de s\u00edntesis de texto a voz (TTS).</p>"},{"location":"ia/introduccion/campos.html#asistentes-virtuales-y-recomendadores","title":"Asistentes virtuales y recomendadores.","text":"<p>En diversas modalidades, asistentes virtuales como Alexa, Siri o Google est\u00e1n ingresando en los hogares con el prop\u00f3sito de simplificar la automatizaci\u00f3n del entorno dom\u00e9stico a un costo asequible.</p> <p>Los sistemas de recomendaci\u00f3n y otros chatbots tienen la funci\u00f3n de desempe\u00f1ar el rol de asistentes de ventas. Cuando se combinan con t\u00e9cnicas de visi\u00f3n mejorada y realidad aumentada, permiten a los usuarios visualizar c\u00f3mo les quedar\u00eda una prenda espec\u00edfica o les sugieren otros productos que podr\u00edan interesarles, bas\u00e1ndose en la relaci\u00f3n de datos de compras realizadas por otros usuarios que han adquirido productos similares.</p>"},{"location":"ia/introduccion/campos.html#ciencias-de-datos-y-data-mining","title":"Ciencias de datos y Data Mining","text":"<p>Dentro del \u00e1mbito de la ciencia de datos, la inteligencia artificial ha tenido un impacto significativo al permitir la identificaci\u00f3n de patrones y relaciones a trav\u00e9s de m\u00e9todos no supervisados. Adem\u00e1s, facilita la realizaci\u00f3n de agrupaciones y aplicaciones heur\u00edsticas. Existen diversos algoritmos y herramientas disponibles, como por ejemplo, nVidia RAPIDS, que utiliza los n\u00facleos CUDA de una unidad de procesamiento gr\u00e1fico (GPU) para acelerar el proceso de entrenamiento y la inferencia en redes neuronales. En este campo, tambi\u00e9n se incluyen heur\u00edsticas y sistemas de detecci\u00f3n de anomal\u00edas que se aplican en el \u00e1mbito del mantenimiento industrial.</p>"},{"location":"ia/introduccion/campos.html#ciberseguridad","title":"Ciberseguridad.","text":"<p>Sistemas como nVidia Morpheus pueden hacer las funciones de un IDS (Intruder Detector System) mediante la b\u00fasqueda de anomal\u00edas en el tr\u00e1fico de red.</p>"},{"location":"ia/introduccion/clases.html","title":"Clases de inteligencia artificial.","text":"<p>Se escriben muchas exageraciones acerca de la inteligencia artificial en los medios de comunicaci\u00f3n. Una de las razones es que con \"inteligencia artificial\" se expresan muchas cosas, pero podr\u00edamos destacar dos de ellas, dos ideas separadas que se refieren a cosas muy diferentes.</p> <p>Por un lado, casi todo el progreso que estamos viendo en la inteligencia artificial se agrupa en lo que se denomina inteligencia artificial d\u00e9bil (Narrow Artificial Intelligence). Pero con inteligencia artificial tambi\u00e9n nos referimos a un segundo concepto, nombrado inteligencia artificial fuerte (General Artificial Intelligence). Este tipo de inteligencia es aquella que considera que las m\u00e1quinas pueden hacer cualquier cosa que un humano pueda hacer, o ser superinteligentes y hacer incluso m\u00e1s cosas.</p> <p>Si bien hay muchos progresos en el \u00e1rea de la inteligencia artificial d\u00e9bil, no hay casi ninguno en lo que se refiere a la inteligencia artificial fuerte. Pero el r\u00e1pido progreso en la inteligencia artificial d\u00e9bil, que es incre\u00edblemente valioso, ha hecho que los medios de comunicaci\u00f3n a veces concluyan que hay mucho progreso tambi\u00e9n en la fuerte, lo cual no es cierto en estos momentos. La inteligencia artificial fuerte es un \u00e1mbito en el que los investigadores pueden trabajar, pero en el que se est\u00e1 a\u00fan muy lejos de conseguir un gran conocimiento; pueden pasar d\u00e9cadas o cientos de a\u00f1os, qui\u00e9n sabe.</p> <p>Un ejemplo. Incluso un ni\u00f1o de tres a\u00f1os puede aprender cosas de una manera que las computadoras no pueden hacerlo por ahora; una ni\u00f1o de tres a\u00f1os en realidad domina la f\u00edsica intuitivamente. Por ejemplo, sabe perfectamente que cuando tira una bola al aire esta caer\u00e1. O cuando derrama algunos l\u00edquidos espera el desastre resultante. Sus padres no necesitan ense\u00f1arle las leyes de Newton, o hablarle de las ecuaciones diferenciales que definen la trayectoria de los objetos; este ni\u00f1o descubre todas estas cosas solo, sin supervisi\u00f3n.</p> <p>Ahora bien, hay autores que consideran que incluso s\u00f3lo con la inteligencia artificial d\u00e9bil nos dirigimos r\u00e1pidamente hacia una situaci\u00f3n en la que los sistemas inform\u00e1ticos tomar\u00e1n decisiones por nosotros, y piden que nos preguntemos qu\u00e9 suceder\u00e1 cuando esos sistemas dejen de lado la estrategia humana en favor de algo totalmente desconocido para nosotros.</p> <p></p>"},{"location":"ia/introduccion/clases.html#el-test-de-turing","title":"El test de Turing.","text":"<p>El matem\u00e1tico brit\u00e1nico Alan Turing (1912-1954) es considerado uno de los padres de las Ciencias de la Computaci\u00f3n. Entre muchas de sus contribuciones formul\u00f3 la prueba que lleva su nombre. Seg\u00fan este investigador, un ordenador que fuese capaz el test de Turing se podr\u00eda considerar inteligente.</p> <p>El test de Turing consiste en hacer que una persona hable a trav\u00e9s de una pantalla y un teclado simult\u00e1neamente con un grupo de individuos entre los que se esconde un ordenador. A la vista de las respuestas que recibe de cada uno de ellos, esta persona deber\u00eda ser capaz de saber qui\u00e9n es el ordenador y qui\u00e9nes son los seres humanos. Si el ordenador no es descubierto, se podr\u00eda considerar que ha pasado el test de Turing. Dado que la conversaci\u00f3n se lleva a cabo en forma de texto, a trav\u00e9s de un teclado y un monitor, no es necesario que la m\u00e1quina sea capaz de transformar el texto en voz, aunque estoy hoy en d\u00eda ya es posible. Esta prueba no eval\u00faa conocimientos, dado que un ser humano no lo sabe todo, sino que lo que mide es la capacidad de una m\u00e1quina de conversar como lo har\u00eda un ser humano.</p> <p>Ya han pasado m\u00e1s de 70 a\u00f1os desde que se enunciara el test de Turing y hay m\u00e1quinas que han conseguido superarla.</p>"},{"location":"ia/introduccion/definicion.html","title":"Definici\u00f3n de inteligencia artificial.","text":"<p>La Inteligencia Artificial (IA), al igual que la humana, es un concepto complejo de definir. A\u00fan no existe una definici\u00f3n formal y universalmente aceptada.</p> <p>La Comisi\u00f3n Europea la define como sistemas de software (y posiblemente tambi\u00e9n de hardware) dise\u00f1ados por humanos que, ante un objetivo complejo, act\u00faan en la dimensi\u00f3n f\u00edsica o digital:</p> <ul> <li>Percibiendo su entorno, a trav\u00e9s de la adquisici\u00f3n e interpretaci\u00f3n de datos estructurados o no estructurados.</li> <li>Razonando sobre el conocimiento, procesando la informaci\u00f3n derivada de estos datos y decidiendo las mejores acciones para lograr el objetivo dado.</li> </ul> <p>Los sistemas de IA pueden usar reglas simb\u00f3licas o aprender un modelo num\u00e9rico. Tambi\u00e9n pueden adaptar su comportamiento al analizar c\u00f3mo el medio ambiente se ve afectado por sus acciones previas.</p> <p>La inteligencia artificial (IA) es un campo de la inform\u00e1tica que se enfoca en crear sistemas que puedan realizar tareas que normalmente requieren inteligencia humana, como el aprendizaje, el razonamiento y la percepci\u00f3n. Estos sistemas pueden percibir su entorno, razonar sobre el conocimiento, procesar la informaci\u00f3n derivada de los datos y tomar decisiones para lograr un objetivo dado.</p> <p></p>"},{"location":"ia/introduccion/historia.html","title":"Historia de la inteligencia artificial.","text":""},{"location":"ia/introduccion/historia.html#inicios-de-la-inteligencia-artificial-optimismo-inicial-desde-los-anos-40-hasta-mediados-de-los-60","title":"Inicios de la inteligencia artificial. Optimismo inicial (desde los a\u00f1os 40 hasta mediados de los 60)","text":"<p>Los fundamentos de los paradigmas de desarrollo de la Inteligencia Artificial (IA) que dominan en la actualidad se originaron en investigaciones que se llevaron a cabo antes de 1956.</p> <p>En 1943, Warren McCulloch y Walter Pitts desarrollaron un modelo pionero basado en la teor\u00eda computacional de Alan Turing. Este modelo consist\u00eda en neuronas artificiales que pod\u00edan activarse o desactivarse seg\u00fan los est\u00edmulos recibidos de neuronas cercanas. Sosten\u00edan la idea de que redes neuronales de este tipo ten\u00edan el potencial de \"aprender\", marcando as\u00ed el surgimiento del paradigma conexionista que se explorar\u00eda posteriormente.</p> <p>En ese mismo a\u00f1o, se introdujeron los principios del paradigma simb\u00f3lico al interpretar el conocimiento humano en t\u00e9rminos de descripciones declarativas y m\u00f3dulos de entidades simb\u00f3licas de alto nivel, junto con un conjunto de reglas de inferencia para manipular estas descripciones simb\u00f3licas.</p> <p>En 1950, el trabajo de Alan Turing complement\u00f3 a\u00fan m\u00e1s los cimientos del paradigma simb\u00f3lico al proponer un m\u00e9todo experimental para evaluar la inteligencia contenida en un \"programa de IA\", que ahora conocemos como el \"Test de Turing\". Tambi\u00e9n introdujo conceptos como el aprendizaje autom\u00e1tico, los algoritmos gen\u00e9ticos y el aprendizaje por refuerzo en su obra.</p> <p>En 1956, se lleg\u00f3 a un consenso sobre la adopci\u00f3n del t\u00e9rmino \"Inteligencia Artificial\" para englobar los avances en estos campos. Esto condujo al desarrollo de herramientas como el Sistema de Resoluci\u00f3n General de Problemas (SRGP), dise\u00f1ado para imitar los procesos de resoluci\u00f3n de problemas humanos, y el lenguaje de programaci\u00f3n LISP, que domin\u00f3 la programaci\u00f3n en IA en esos primeros a\u00f1os.</p> <p>El \u00e9xito de estos avances durante este per\u00edodo gener\u00f3 predicciones optimistas y a corto plazo sobre el futuro desarrollo de la IA. Sin embargo, como veremos m\u00e1s adelante, estas predicciones chocaron con la realidad al enfrentarse a problemas m\u00e1s complejos y variados en las etapas posteriores.</p>"},{"location":"ia/introduccion/historia.html#la-epoca-oscura-mediados-de-los-60-hasta-mediados-de-los-70","title":"La \u00e9poca oscura (mediados de los 60 hasta mediados de los 70)","text":"<p>Durante este per\u00edodo, se lleg\u00f3 a reconocer que el mundo real era considerablemente m\u00e1s complejo de lo que se hab\u00eda anticipado en etapas anteriores, lo que llev\u00f3 al abandono o desaceleraci\u00f3n de numerosas l\u00edneas de investigaci\u00f3n previas.</p> <p>Los esfuerzos cient\u00edficos y financieros se enfocaron de manera m\u00e1s cautelosa en el dise\u00f1o de t\u00e9cnicas para representar el conocimiento, con el prop\u00f3sito de utilizarlas posteriormente en procesos de inferencia. Paralelamente, se desarrollaron lenguajes de programaci\u00f3n espec\u00edficos para cada una de estas t\u00e9cnicas de representaci\u00f3n, como Prolog para la l\u00f3gica y Lisp para las reglas.</p> <p>En este per\u00edodo se acept\u00f3 que muchos de los problemas que se hab\u00edan intentado abordar mediante la Inteligencia Artificial resultaban, en la pr\u00e1ctica, intratables. Es decir, no exist\u00eda una base cient\u00edfica s\u00f3lida para resolver estos problemas mediante enfoques de ingenier\u00eda. Un ejemplo de esto fue el intento de desarrollar sistemas de traducci\u00f3n autom\u00e1tica, una idea atractiva en una \u00e9poca marcada por la Guerra Fr\u00eda y la inversi\u00f3n en proyectos de \u00edndole militar.</p> <p>Inicialmente, se cre\u00eda err\u00f3neamente que la limitaci\u00f3n principal resid\u00eda en la capacidad de c\u00e1lculo de las m\u00e1quinas de la \u00e9poca. Sin embargo, con el tiempo se comprob\u00f3 que, a pesar de dedicar un gran n\u00famero de horas de procesamiento a la resoluci\u00f3n de problemas, no se lograban alcanzar los objetivos planteados.</p>"},{"location":"ia/introduccion/historia.html#renacimiento-de-la-ia-finales-de-los-anos-70","title":"Renacimiento de la IA (finales de los a\u00f1os 70)","text":"<p>En esta etapa, se volvieron a enfocar los esfuerzos de desarrollo en la soluci\u00f3n de problemas utilizando sistemas expertos que se basaban en reglas y principios cient\u00edficos claramente definidos. Como resultado, comenzaron a surgir programas especializados para dominios muy espec\u00edficos. Por ejemplo, programas como DENDRAL y Mycin pudieron deducir la estructura de ciertas mol\u00e9culas a partir de datos de espectrometr\u00eda de masas y diagnosticar enfermedades infecciosas en muestras de sangre a partir de datos m\u00e9dicos, respectivamente.</p> <p>Este aumento generalizado en la aplicaci\u00f3n de la IA para abordar problemas del mundo real condujo a una mayor demanda de esquemas de representaci\u00f3n del conocimiento efectivos, lo que a su vez dio lugar al desarrollo de nuevos lenguajes de programaci\u00f3n.</p>"},{"location":"ia/introduccion/historia.html#desarrollo-industrial-y-economico-de-los-80-hasta-la-actualidad","title":"Desarrollo industrial y econ\u00f3mico (de los 80 hasta la actualidad)","text":"<p>Comienzan a desarrollarse sistemas expertos aplicados a la industria que suponen, en la pr\u00e1ctica, un considerable beneficio econ\u00f3mico para las empresas que los implementan.</p> <p>A mediados de los a\u00f1os 80 se recuper\u00f3 el planteamiento de redes neuronales que dio base al modelo conexionista al redise\u00f1ar el algoritmo de aprendizaje con realimentaci\u00f3n aplic\u00e1ndolo a diversos problemas de aprendizaje en los campos de la inform\u00e1tica y la psicolog\u00eda. </p> <p>En los \u00faltimos a\u00f1os y hasta nuestros d\u00edas se han centrado los esfuerzos en el \u00e1rea de la IA en la mejora de las teor\u00edas ya existentes, en lugar de tratar de idear nuevas v\u00edas de desarrollo sin una base experimental y cient\u00edfica s\u00f3lidas. </p> <p>La IA ya ha adoptado el m\u00e9todo cient\u00edfico, por lo que las hip\u00f3tesis que postula se deben someter a rigurosos experimentos emp\u00edricos, y los resultados deben analizarse estad\u00edsticamente para identificar su relevancia. </p> <p>Se est\u00e1n desarrollando sistemas de razonamiento incierto como las redes de Bayes que permiten facilitar la representaci\u00f3n eficiente y el razonamiento riguroso en situaciones y problemas de incertidumbre. </p> <p>Los principales avances ocurridos en las \u00faltimas d\u00e9cadas ser\u00edan:</p> <ul> <li>D\u00e9cada de 2000: Avances en el aprendizaje profundo permiten mejoras en reconocimiento de voz y visi\u00f3n artificial.</li> <li>D\u00e9cada de 2010: La IA se convierte en parte integral de la vida cotidiana a trav\u00e9s de asistentes virtuales y veh\u00edculos aut\u00f3nomos.</li> <li>D\u00e9cada de 2020: La IA se utiliza en la medicina, la investigaci\u00f3n cient\u00edfica y la toma de decisiones empresariales.</li> </ul> <p>El futuro de la IA promete avances emocionantes en campos como la rob\u00f3tica, la IA cu\u00e1ntica y la \u00e9tica de la inteligencia artificial. A medida que la tecnolog\u00eda contin\u00faa evolucionando, la inteligencia artificial seguir\u00e1 transformando la forma en que vivimos y trabajamos.</p>"},{"location":"ia/introduccion/introduccion.html","title":"Introducci\u00f3n","text":"<p>Algunos autores comienzan a considerar la inteligencia artificial (Artificial Intelligence, AI) como la nueva revoluci\u00f3n industrial, coraz\u00f3n de lo que algunos llaman industria 4.0.</p> <p>Nos encontramos ante vertiginosos avances en la calidad y prestaciones de una amplia gama de tecnolog\u00edas cotidianas: en el caso del reconocimiento de voz autom\u00e1tica (Automated Speech Recognition, ASR), un asistente virtual de atenci\u00f3n al cliente en el servicio de chat en l\u00ednea de muchas empresas. Estos asistentes virtuales, a menudo impulsados tambi\u00e9n por sistemas de procesado de lenguaje natural, son capaces de comprender y responder a las preguntas y consultas de los clientes de manera natural y conversacional.</p> <p>Tambi\u00e9n ha habido avances espectaculares en el procesado de lenguaje natural (Natural Language Processing, NLP). Por ejemplo, su uso en la detecci\u00f3n y an\u00e1lisis de sentimientos en redes sociales. Muchas empresas y organizaciones utilizan sistemas de NLP para monitorear y comprender las opiniones y emociones expresadas por los usuarios en plataformas como Twitter, Facebook e Instagram.</p> <p>Incluso m\u00e1s relevante en el \u00e1mbito del NLP es lo que ocurre con el texto predictivo y la redacci\u00f3n autom\u00e1tica en proyecto como el GPT de la fundaci\u00f3n OpenAI. Esta avanzada red neuronal basada en el procesamiento de lenguaje natural ha demostrado su val\u00eda en una amplia gama de aplicaciones, desde la generaci\u00f3n de texto automatizada hasta la traducci\u00f3n de idiomas, la creaci\u00f3n de contenido, la atenci\u00f3n al cliente virtual y mucho m\u00e1s. </p> <p>A su vez, los avances en la visi\u00f3n por computador (Computer Vision, CV) tambi\u00e9n son enormes: ahora nuestros ordenadores, por ejemplo, pueden reconocer im\u00e1genes y generar descripciones textuales de su contenido en segundos. O la perfecci\u00f3n que est\u00e1n alcanzando los generadores de rostros artificiales, que permite que se mezclen personajes reales y ficticios con total realismo.</p> <p>Estas tres \u00e1reas (ASR, NLP y CV) son cruciales para dar rienda suelta a las mejoras en rob\u00f3tica, drones o autom\u00f3viles sin conductor. La inteligencia artificial est\u00e1 en el coraz\u00f3n de toda esta innovaci\u00f3n tecnol\u00f3gica.</p>"},{"location":"ia/modelos/expertos.html","title":"Sistemas basados en reglas. Sistemas expertos","text":"<p>El dise\u00f1o de los sistemas basados en reglas, m\u00e1s conocidos como sistemas expertos, hacen uso de un conjunto de reglas del tipo SI\u2026ENTONCES, conocidas en ingl\u00e9s como IF\u2026THEN. Mediante este conjunto de reglas pueden realizar deducciones o elegir entre distintas alternativas. Estos sistemas expertos son programas de ordenador capaces de simular algunas de las caracter\u00edsticas del conocimiento humano con el fin de realizar tareas que normalmente llevan a cabo \u00fanicamente personas expertas.</p> <p>Todo sistema basado en reglas consta, al menos, de cuatro componentes principales:</p> <ul> <li>Una lista de reglas, que constituye la base de datos de conocimiento que emplear\u00e1.</li> <li>Un motor de inferencias que combina la informaci\u00f3n disponible en cada momento con la lista de reglas para producir el razonamiento.</li> <li>Un sistema para la explicaci\u00f3n de las decisiones tomadas debe disponer de alg\u00fan tipo de subsistema que permita presentar una explicaci\u00f3n de las decisiones tomadas de manera que resulte comprensible para el usuario.</li> <li>Un sistema para la adquisici\u00f3n de nuevo conocimiento que permita a un experto en el campo introducir nueva informaci\u00f3n en el sistema.</li> <li>Un interfaz de usuario que permita alg\u00fan tipo de conexi\u00f3n exterior.</li> </ul> <p>La ventaja fundamental de este tipo de sistemas es que tienen un mecanismo cuyo funcionamiento es f\u00e1cil de entender, se pueden construir haciendo uso de conocimiento experto y se aplican en cualquier campo.</p> <p>Entre las desventajas hay que destacar que antes problemas dif\u00edciles, la generaci\u00f3n de reglas se puede volver un proceso de alta complejidad.</p> <p>Los sistemas expertos desarrollados en los \u00faltimos a\u00f1os no se limitan a la implementaci\u00f3n de reglas, sino que las combinan con metodolog\u00edas propias del Machine Learning.</p>"},{"location":"ia/modelos/impreciso.html","title":"Sistemas de razonamiento impreciso","text":"<p>Los sistemas de razonamiento pueden describirse por la exactitud que necesitan al realizar cualquier paso de su proceso de razonamiento. Los sistemas de razonamiento m\u00e1s preciso son aquellos que s\u00f3lo se ocupan de las relaciones l\u00f3gicamente v\u00e1lidas, conocidas con certeza. En estos casos, las conclusiones son verdaderas, si las premisas son verdaderas.</p> <p>Existen metodolog\u00edas que permiten el razonamiento bajo condiciones de incertidumbre. El uso de estos sistemas cobra gran importancia cuando se trata de construir agentes que van a operar en situaciones reales en las que, por tanto, se manejar\u00e1 incertidumbre.</p> <p>Entre las aproximaciones existentes para el manejo de la incertidumbre se incluyen el uso de m\u00e9todos probabil\u00edsticos como las redes bayesianas y la l\u00f3gica difusa.</p>"},{"location":"ia/modelos/impreciso.html#redes-bayesianas","title":"Redes bayesianas","text":"<p>El teorema de Bayes nos permite actualizar las probabilidades de variables cuyo estado no hemos observado dada una serie de nuevas observaciones. Las redes bayesianas automatizan este proceso, permitiendo que el razonamiento avance en cualquier direcci\u00f3n a trav\u00e9s de la red de variables. Las redes bayesianas est\u00e1n constituidas por una estructura en forma de grafo, en la que cada nodo representa variables aleatorias (discretas o continuas) y cada arista representa las conexiones directas entre ellas.</p> <p>No entraremos en detalle del funcionamiento de una red bayesiana, aunque s\u00ed veremos el teorema de Bayes, que se usa en numerosos \u00e1mbitos de la vida real.</p> <p>La probabilidad de ocurrencia de un evento A se expresa como:</p> <p>$$ P(A) = {n\u00ba\\_ocurrencias\\_A \\over n\u00ba\\_total\\_eventos} $$</p> <p>La probabilidad de ocurrencia de un evento A condicionada a que ocurra otro evento B se especifica mediante el teorema de Bayes de la forma:</p> <p>$$ P(A|B) = {P(B|A) * P(A) \\over P(B)} $$</p>"},{"location":"ia/modelos/impreciso.html#ejemplo-infeccion-zombi","title":"Ejemplo. Infecci\u00f3n zombi","text":"<p>Una nueva epidemia se extiende por Elche. Los afectados se convierten en zombis apenas un par de d\u00edas despu\u00e9s del contagio. La prevalencia de esta epidemia es de 5 infectados por cada mil habitantes. Para intentar controlar la epidemia se ha desarrollado un test de ant\u00edgenos muy preciso, con una sensibilidad del 99.9% y especificidad de 99.0%. Realmente es un test muy bueno. Cuando hay infecci\u00f3n zombi, el test da positivo el 99.9% de las veces y negativo el 0.1%. Cuanto no hay infecci\u00f3n zombi, el test da negativo el 99.0% de las veces y positivo el 1.0%.</p> <p>Lo podemos ver mejor en la siguiente tabla:</p> Infecci\u00f3n zombi No infecci\u00f3n Test positivo 0,999 (verdaderos positivos) 0,010 (falsos positivos) Test negativo 0,001 (falsos negativos) 0,990 (verdaderos negativos) <p>Has ido a una fiesta y sospechas que puedes haberte contagiado, pero no sabes si est\u00e1s infectado o no, por lo que recurres a hacerte un test. Lamentablemente, el test da un resultado POSITIVO.</p> <p>PANICO: el test te est\u00e1 diciendo que con un 99.9% de probabilidad est\u00e1s contagiado, eso es casi una certeza. Una vez superado el shock inicial, asumes lo inevitable y te preparas para lo peor, pero hay algo que no cuadra\u2026</p> <p>Si hubiese recurrido a Bayes desde el principio me habr\u00eda ahorrado el susto:</p> <p>$$ P(infeccion|test\\_positivo) = {P(test\\_positivo|infeccion) * P(infeccion) \\over P(test\\_positivo)} $$</p> <p>$$ P(test\\_positivo) = P(verdadero\\_positivo) * P(infeccion) + P(falso\\_positivo ) \u2217 P(no\\_infeccion)$$</p> <p>$$ P(test\\_positivo) = 0.999 \u2217 0.005 + 0.01 \u2217 0.995 = 0.015 $$</p> <p>$$ P(infeccion|test\\_positivo)= {0.999 \u2217 0.005 \\over 0.015} = 0.33 $$</p> <p>\u00a1Menudo susto! Tengo un 33% de probabilidad de estar infectado. Mis posibilidades son mucho mejores de lo hab\u00eda imaginado inicialmente.</p>"},{"location":"ia/modelos/impreciso.html#logica-difusa","title":"L\u00f3gica difusa","text":"<p>La l\u00f3gica difusa es capaz de procesar distintos grados de verdad, pero estos no deben ser interpretados en el sentido de probabilidades, pues lo que representan dentro del \u00e1mbito de la l\u00f3gica difusa es la probabilidad de pertenencia a cierto conjunto, en vez de la probabilidad de que ocurra un evento.</p> <p>Un ejemplo. Si se dispone de una botella numerada como 1 con agua que tiene un grado de pertenencia difuso del 80% al conjunto de agua potable. Por otro lado, la botella numerada como 2 tiene una probabilidad del 80% de ser potable. \u00bfDe qu\u00e9 botella es menos arriesgado beber?</p> <p>Se ha de interpretar que la primera botella tiene un contenido de agua que es bastante similar al de otras botellas que son potables, alrededor de un 80%, mientras que en el caso de la segunda botella lo que se quiere decir es que, si se bebe el agua de una botella de ese tipo, el 80% de las veces que se han analizado conten\u00edan agua potable. Pero cuidado, que en un 20% de las ocasiones su contenido completo era de agua no potable.</p>"},{"location":"ia/modelos/introduccion.html","title":"Introducci\u00f3n","text":"<p>En la era digital actual, los modelos de inteligencia artificial (IA) se han convertido en protagonistas indiscutibles, desempe\u00f1ando un papel fundamental en una amplia variedad de aplicaciones y sectores, desde la asistencia virtual en el hogar hasta diagn\u00f3sticos m\u00e9dicos avanzados y la optimizaci\u00f3n de la cadena de suministro. Estos modelos son el resultado de d\u00e9cadas de investigaci\u00f3n en aprendizaje autom\u00e1tico, procesamiento de lenguaje natural, visi\u00f3n por computadora y m\u00e1s.</p> <p>En este apartado se har\u00e1 un breve repaso por algunos de los modelos existentes en Inteligencia Artificial, detallando no s\u00f3lo aquellos pertenecientes al \u00e1mbito del Machine Learning.</p>"},{"location":"ia/modelos/machine.html","title":"Sistemas de aprendizaje autom\u00e1tico. Machine Learning","text":"<p>El Machine Learning, traducido al castellano como aprendizaje autom\u00e1tico, es la ciencia de programar ordenadores para que aprendan a partir de datos. Esto otorga a los ordenadores la capacidad de aprender sin ser programados de manera expl\u00edcita.</p> <p>Se dice que un programa de ordenador aprende de la experiencia E, con respecto a una tarea T y una medida de rendimiento R, si su rendimiento en T, medido por P, mejora con la experiencia E.</p> <p>El filtro de spam es un programa de machine learning que, al recibir ejemplos de correo basura (marcados por los usuarios) y ejemplos de correos corrientes (que no sean spam, tambi\u00e9n llamados \u201cham\u201d), puede aprender a marcar el spam. Los ejemplos que el sistema utiliza para aprender se llaman conjunto de entrenamiento. Cada ejemplo de entrenamiento se llama instancia de entrenamiento (o muestra). La parte de un sistema de machine learning que aprende y realiza predicciones se denomina modelo. Las redes neuronales y los random forests son ejemplos de modelos.</p> <p>En este caso, la tarea T es marcar el spam para los correos nuevos, la experiencia E son los datos de entrenamiento y la medida del rendimiento tiene que definirse; por ejemplo, podemos utilizar la proporci\u00f3n de correos clasificados correctamente.</p>"},{"location":"ia/modelos/machine.html#deep-learning","title":"Deep Learning","text":"<p>Como hemos mencionado anteriormente las redes neuronales son un modelo dentro de los sistemas de Machine Learning. Estas redes neuronales artificiales pretenden imitar en cierta manera la actividad de las capas de neuronas en la neocorteza del cerebro humano donde ocurre el pensamiento. Estas redes neuronales artificiales se organizan jer\u00e1rquicamente en capas de procesamiento (construidas con neuronas artificiales). Una red neuronal se considera Deep Learning cuando tiene una o m\u00e1s capas ocultas.</p> <p></p> <p>Los grandes avances en reconocimiento de voz, procesado de lenguaje natural o visi\u00f3n por computador, son debidos en gran parte a los avances del Deep Learning en esta \u00faltima d\u00e9cada.</p> <p></p>"},{"location":"ia/modelos/problemas.html","title":"Sistemas de resoluci\u00f3n de problemas","text":"<p>Todo sistema de resoluci\u00f3n de problemas debe ser capaz de evolucionar hasta alcanzar una de las posibles soluciones del problema.</p> <p>Los sistemas de resoluci\u00f3n de problemas tienen como objetivo alcanzar alguno de los estados en los que el problema se puede considerar resuelto. A la hora de formular que el sistema sea capaz de alcanzar la soluci\u00f3n, es necesario que el medio donde \u00e9ste se formula cumpla una serie de caracter\u00edsticas:</p> <ul> <li>En primer lugar, que sea observable para el sistema de resoluci\u00f3n de problemas. Es decir, que de alguna forma este sistema pueda reconocer y explorar el medio en su totalidad.</li> <li>En segundo lugar, resulta conveniente que el medio sea finito y determinista, entendiendo como tal que ejercer la misma acci\u00f3n sobre el medio, conduzca siempre al mismo resultado.</li> </ul> <p>As\u00ed, si el medio es observable, finito y determinista, la resoluci\u00f3n de cualquier problema consistir\u00e1 en la ejecuci\u00f3n de un n\u00famero finito de pasos.</p> <p>El proceso mediante el que, haciendo uso de una secuencia de acciones, el sistema de resoluci\u00f3n de problemas alcanza el objetivo, se denomina b\u00fasqueda.</p> <p>Este tipo de sistemas disponen de los siguientes componentes:</p> <ul> <li>Estado inicial: se trata del estado desde el que se comenzar\u00e1 el proceso de b\u00fasqueda.</li> <li>Acciones que se pueden ejecutar: en funci\u00f3n del problema con el que se est\u00e9 trabajando, el sistema dispondr\u00e1 de una serie de posibles acciones que le permitir\u00e1n pasar de un estado a otro.</li> <li>Modelo de transici\u00f3n: explica lo que har\u00e1 cada una de esas acciones.</li> <li>Espacio de estados del problema: se trata del conjunto de todas las posibles situaciones a las que se puede llegar a partir del punto de partida.</li> <li>Verificaci\u00f3n de que se ha alcanzado el objetivo, que determina si la posici\u00f3n lograda es una de las posiciones objetivo.</li> <li>Coste de ejecuci\u00f3n: en muchos casos, puede resultar de inter\u00e9s el saber cu\u00e1nto cuesta ejecutar cada una de las acciones que son necesarias para llegar al objetivo.</li> </ul>"},{"location":"ia/modelos/problemas.html#ejemplo-juego-de-varios-competidores-tres-en-raya","title":"Ejemplo. Juego de varios competidores: tres en raya","text":"<p>Vamos a ver un problema cl\u00e1sico de la IA: los juegos. La situaci\u00f3n m\u00e1s sencilla, en la que nos centraremos en aras de la claridad, son los juegos de dos jugadores de informaci\u00f3n perfecta, como el tres en raya y el ajedrez.</p>"},{"location":"ia/modelos/problemas.html#arboles-de-juego","title":"\u00c1rboles de juego","text":"<p>Los distintos estados del juego se representan mediante nodos en el \u00e1rbol de juego. En el \u00e1rbol de juego, los nodos est\u00e1n dispuestos en niveles que se corresponden con los turnos de cada jugador, de forma que el nodo \u00abra\u00edz\u00bb del \u00e1rbol (normalmente representado en la parte superior del diagrama) es la posici\u00f3n inicial en el juego. En el tres en raya, ser\u00eda la cuadr\u00edcula vac\u00eda, sin X ni O. Debajo de la ra\u00edz, en el segundo nivel, se representan los estados que pueden derivarse de los primeros movimientos de los jugadores, ya sea X o O. Nos referimos a estos nodos como los \u00abhijos\u00bb del nodo ra\u00edz.</p> <p>A su vez, cada nodo del segundo nivel tendr\u00e1 como nodos hijos los estados que pueden resultar de \u00e9l en funci\u00f3n de los movimientos del jugador contrincante. Esta situaci\u00f3n prosigue, nivel a nivel, hasta alcanzar estados en los que el juego finaliza. En el tres en raya, esto significa que uno de los jugadores consigue colocar tres fichas en l\u00ednea y gana, o que el tablero est\u00e1 completo y el juego termina en empate.</p> <p></p>"},{"location":"ia/modelos/problemas.html#valor-minimizante-y-maximizante","title":"Valor m\u00ednimizante y maximizante","text":"<p>Para desarrollar un m\u00e9todo de IA que trate de ganar el juego, asignamos un valor num\u00e9rico a cada resultado final posible. A las posiciones del tablero en las que hay tres X en raya de forma que Max gana les asignamos el valor +1, y, del mismo modo, a las posiciones en que Min gana con tres O en raya les asignamos el valor -1. Para las posiciones en que el tablero est\u00e1 lleno y ninguna de las jugadoras gana, utilizamos el valor neutral 0 (realmente no importa cu\u00e1les sean los valores mientras sigan este orden, de forma que Max intente maximizar el valor y Min, minimizarlo).</p> <p> </p>"},{"location":"ia/modelos/problemas.html#crecimiento-del-arbol-ramificacion-y-poda","title":"Crecimiento del \u00e1rbol. Ramificaci\u00f3n y poda","text":"<p>Un problema com\u00fan es el r\u00e1pido crecimiento del \u00e1rbol de estados. \u00a1En el problema del tres en raya, el espacio de estados es 9! (factorial de 9), o lo que es lo mismo 9x8x7x6x5x4x3x2x1=362.880 jugadas posibles.</p> <p>En el caso del ajedrez, se considera que cada jugada tiene un nivel de multiplicaci\u00f3n de 35, es decir, 35 alternativas por cada estado. En dos niveles, ser\u00eda 35x35=1.225 movimientos posibles. En 5 niveles tendr\u00edamos 52.521.875 movimientos. En 10 niveles m\u00e1s de 2.700 millones de jugadas.</p> <p>Por muy r\u00e1pido que sea el sistema inform\u00e1tico, la posibilidad de explorar todo el \u00e1rbol de decisi\u00f3n es pr\u00e1cticamente imposible.</p> <p>Hace falta alg\u00fan tipo de algoritmo que limite la b\u00fasqueda en el espacio de estados. Algunos de estos algoritmos ser\u00edan el de poda alfa-beta o el de poda heur\u00edstica.</p>"},{"location":"ia/tipos_aa/instancias.html","title":"Aprendizaje basado en instancias frente a aprendizaje basado en modelos","text":"<p>Otra manera de categorizar los sistemas de machine learning es fijarse en c\u00f3mo generalizan. La mayor\u00eda de las tareas de machine learning tienen que ver con hacer predicciones. Eso significa que, si se le da a un sistema una cantidad de ejemplos de entrenamiento, este tiene que ser capaz de hacer buenas predicciones para (generalizar a) ejemplos que nunca ha visto antes. Tener una buena medida del rendimiento en los datos de entrenamiento est\u00e1 bien, pero no es suficiente; el verdadero objetivo es tener un buen rendimiento en instancias nuevas.</p> <p>Hay dos enfoques principales para la generalizaci\u00f3n: el aprendizaje basado en instancias y el aprendizaje basado en modelos.</p>"},{"location":"ia/tipos_aa/instancias.html#aprendizaje-basado-en-instancias","title":"Aprendizaje basado en instancias","text":"<p>Una forma de aprendizaje bastante sencilla implica la memorizaci\u00f3n pura y simple. Imaginemos que creamos un filtro de spam de esta manera: simplemente marcar\u00eda como spam cualquier correo electr\u00f3nico id\u00e9ntico a los que los usuarios previamente hayan se\u00f1alado como spam. Si bien esta no es la peor soluci\u00f3n, ciertamente no es la m\u00e1s efectiva.</p> <p>En lugar de limitarse a marcar correos id\u00e9nticos a los conocidos como spam, el filtro podr\u00eda programarse para identificar tambi\u00e9n correos que compartan muchas similitudes con correos previamente etiquetados como spam. Para lograrlo, se requiere medir la similitud entre dos correos. Una medida de similitud bastante b\u00e1sica podr\u00eda ser contar la cantidad de palabras en com\u00fan. El sistema etiquetar\u00eda un correo como spam si comparte muchas palabras con un correo de spam previamente registrado.</p> <p>Este enfoque se conoce como \"aprendizaje basado en instancias\". El sistema aprende ejemplos y los almacena en memoria, y luego generaliza para clasificar nuevos casos utilizando una medida de similitud que los compara con los ejemplos aprendidos (o un subconjunto de ellos). Por ejemplo, en la siguiente figura, la nueva instancia se clasificar\u00eda como un tri\u00e1ngulo porque comparte una mayor similitud con ejemplos previos de esa clase.</p> <p></p>"},{"location":"ia/tipos_aa/instancias.html#aprendizaje-basado-en-modelos","title":"Aprendizaje basado en modelos","text":"<p>Otra forma de generalizar a partir de un conjunto de ejemplos es crear un modelo de esos ejemplos y, despu\u00e9s, utilizarlo para hacer predicciones. Esto se denomina \u201caprendizaje basado en modelos\u201d.</p> <p></p>"},{"location":"ia/tipos_aa/introduccion.html","title":"Introducci\u00f3n","text":"<p>Podemos clasificar los sistemas de machine learning seg\u00fan los siguientes criterios:</p> <ul> <li>C\u00f3mo se supervisan durante el entrenamiento (aprendizaje supervisado, aprendizaje no supervisado, aprendizaje semisupervisado, aprendizaje autosupervisado y otros).</li> <li>Si pueden o no aprender de forma gradual sobre la marcha (aprendizaje online frente a aprendizaje por lotes).</li> <li>Si funcionan comparando simplemente puntos de datos nuevos con puntos de datos conocidos o si detectan patrones en los datos de entrenamiento y crean un modelo predictivo, como hacen los cient\u00edficos (aprendizaje basado en instancias frente a aprendizaje basado en modelos).</li> </ul>"},{"location":"ia/tipos_aa/lotes.html","title":"Aprendizaje por lotes frente a aprendizaje online","text":"<p>Otro criterio utilizado para clasificar sistemas de machine learning es si el sistema puede o no aprender de manera gradual a partir de un flujo de datos entrantes.</p>"},{"location":"ia/tipos_aa/lotes.html#aprendizaje-por-lotes","title":"Aprendizaje por lotes","text":"<p>En el enfoque de aprendizaje por lotes, el sistema no tiene la capacidad de aprender de forma incremental; en su lugar, debe ser entrenado utilizando todos los datos disponibles. Por lo general, este proceso requiere un tiempo significativo y recursos computacionales considerables, por lo que suele realizarse de manera offline. Inicialmente, se entrena el sistema, y una vez completado este proceso, se pone en producci\u00f3n y ejecuta sin continuar aprendiendo; simplemente aplica lo que ha aprendido. A este m\u00e9todo se le conoce como aprendizaje offline.</p> <p>Sin embargo, uno de los desaf\u00edos del aprendizaje por lotes es que con el tiempo, el rendimiento del modelo tiende a decaer gradualmente debido a que el mundo sigue evolucionando mientras el modelo permanece est\u00e1tico. Este fen\u00f3meno se denomina \"data drift\" o deriva de datos. La soluci\u00f3n a este problema implica reentrenar regularmente el modelo con datos actualizados. La frecuencia de reentrenamiento var\u00eda seg\u00fan el caso de uso: por ejemplo, si el modelo clasifica im\u00e1genes de gatos y perros, su rendimiento se deteriorar\u00e1 lentamente, mientras que en aplicaciones financieras, donde los datos cambian r\u00e1pidamente, el deterioro puede ser m\u00e1s r\u00e1pido.</p> <p>Si deseamos que un sistema de aprendizaje por lotes se adapte a nuevos datos, como un nuevo tipo de correo no deseado, debemos entrenar una versi\u00f3n completamente nueva del sistema desde cero, utilizando el conjunto de datos completo (tanto los datos nuevos como los antiguos), y luego reemplazar la versi\u00f3n anterior. Afortunadamente, el proceso completo de entrenamiento, evaluaci\u00f3n y lanzamiento de un sistema de aprendizaje autom\u00e1tico puede automatizarse con relativa facilidad, lo que permite que incluso los sistemas de aprendizaje por lotes se adapten a los cambios. Solo debemos actualizar los datos y reentrenar el sistema con la frecuencia requerida.</p> <p></p> <p>Sin embargo, este enfoque presenta algunos desaf\u00edos. El proceso de entrenamiento en el conjunto de datos completo puede ser intensivo en cuanto a recursos, lo que implica un gasto significativo de recursos computacionales (CPU, memoria, espacio en disco, E/S de disco, E/S de red, etc.). Si los datos son abundantes y automatizamos el proceso de entrenamiento desde cero a diario, el costo puede ser considerable. En casos en los que la cantidad de datos es enorme, incluso puede resultar imposible utilizar un algoritmo de aprendizaje por lotes.</p> <p>Por \u00faltimo, si nuestro sistema necesita aprender de manera continua y opera con recursos limitados, como una aplicaci\u00f3n m\u00f3vil o un rover en Marte, llevar grandes conjuntos de datos de entrenamiento y destinar una gran cantidad de recursos para entrenar durante varias horas al d\u00eda puede ser un problema cr\u00edtico. En estos casos, una opci\u00f3n m\u00e1s adecuada es utilizar algoritmos que sean capaces de aprender de forma incremental.</p>"},{"location":"ia/tipos_aa/lotes.html#aprendizaje-online","title":"Aprendizaje online","text":"<p>En el aprendizaje online, entrenamos el sistema de datos de forma gradual al introducir instancias de datos de manera secuencial, ya sea individualmente o en grupos peque\u00f1os llamados minilotes. Cada paso del aprendizaje es r\u00e1pido y barato, as\u00ed que el sistema puede aprender acerca de datos nuevos sobre la marcha, seg\u00fan llegan.</p> <p></p> <p>El enfoque de aprendizaje online resulta beneficioso para sistemas que requieren una r\u00e1pida adaptaci\u00f3n al cambio, como, por ejemplo, aquellos destinados a la detecci\u00f3n de patrones emergentes en el mercado de valores. Tambi\u00e9n se presenta como una excelente opci\u00f3n en situaciones en las que los recursos computacionales son limitados, como en el caso del entrenamiento de modelos en dispositivos m\u00f3viles.</p> <p>Adem\u00e1s, los algoritmos de aprendizaje online permiten el entrenamiento de sistemas en conjuntos de datos de gran magnitud que no caben en la memoria principal de una m\u00e1quina. Este enfoque se denomina aprendizaje \"out of core\" o \"fuera del n\u00facleo\". El algoritmo carga una porci\u00f3n de los datos, realiza un paso de entrenamiento con esos datos y repite el proceso hasta que ha procesado todos los datos disponibles.</p> <p></p> <p>Un aspecto crucial en los sistemas de aprendizaje online es la velocidad con la que deben adaptarse a los datos cambiantes, lo que se conoce como la \"tasa de aprendizaje\". Si configuramos una tasa de aprendizaje alta, el sistema se ajustar\u00e1 r\u00e1pidamente a los nuevos datos, pero tambi\u00e9n corre el riesgo de olvidar con rapidez los datos anteriores. Este \u00faltimo aspecto no es deseable, especialmente en casos como la detecci\u00f3n de spam, donde no queremos que el sistema se centre solo en los tipos m\u00e1s recientes de spam que ha encontrado. Por otro lado, si optamos por una tasa de aprendizaje baja, el sistema aprender\u00e1 de manera m\u00e1s lenta, pero tambi\u00e9n ser\u00e1 menos susceptible al ruido de los nuevos datos o a secuencias de datos at\u00edpicos.</p> <p>Uno de los desaf\u00edos principales del aprendizaje online radica en la posibilidad de que, si se introducen datos de mala calidad en el sistema, su rendimiento pueda degradarse, posiblemente de manera significativa (esto depende de la calidad de los datos y de la tasa de aprendizaje). Esto es particularmente problem\u00e1tico en sistemas en funcionamiento, ya que los clientes pueden notar r\u00e1pidamente el impacto negativo en su experiencia. Los datos de baja calidad pueden originarse a partir de fallas t\u00e9cnicas, como sensores defectuosos en un robot, o de intentos de manipulaci\u00f3n del sistema, como el bombardeo de spam en un motor de b\u00fasqueda para aumentar su visibilidad en los resultados. Para mitigar este riesgo, es esencial monitorear de cerca el sistema y desactivar el aprendizaje de manera inmediata si se detecta una disminuci\u00f3n en el rendimiento. Tambi\u00e9n es importante establecer mecanismos de monitoreo de los datos de entrada y responder a las se\u00f1ales de datos an\u00f3malos, lo que puede lograrse mediante el uso de algoritmos de detecci\u00f3n de anomal\u00edas.</p>"},{"location":"ia/tipos_aa/supervision.html","title":"Supervisi\u00f3n del entrenamiento","text":"<p>Los sistemas de machine learning pueden clasificarse seg\u00fan la cantidad y el tipo de supervisi\u00f3n que tengan durante el entrenamiento.</p>"},{"location":"ia/tipos_aa/supervision.html#aprendizaje-supervisado","title":"Aprendizaje supervisado","text":"<p>En el aprendizaje supervisado, el conjunto de entrenamiento que introducimos en el algoritmo incluye las soluciones deseadas, denominadas \u201cetiquetas\u201d.</p> <p></p> <p>Una tarea com\u00fan en el aprendizaje supervisado es la clasificaci\u00f3n. Un ejemplo ilustrativo es el filtro de correo no deseado (spam): se entrena utilizando una gran cantidad de correos electr\u00f3nicos de muestra junto con su categorizaci\u00f3n (spam o leg\u00edtimo), y debe aprender a clasificar nuevos correos electr\u00f3nicos.</p> <p>Otra tarea frecuente implica predecir un valor num\u00e9rico objetivo, como el precio de un autom\u00f3vil, cuando se proporciona un conjunto de caracter\u00edsticas (kilometraje, antig\u00fcedad, marca, etc.). Este tipo de tarea se conoce como regresi\u00f3n. Para entrenar el sistema en esta tarea, se le proporcionan numerosos ejemplos de autom\u00f3viles, junto con sus caracter\u00edsticas y sus respectivos objetivos (es decir, sus precios).</p> <p></p> <p>Es importante destacar que algunos modelos de regresi\u00f3n pueden utilizarse igualmente para la clasificaci\u00f3n, y viceversa. Por ejemplo, la regresi\u00f3n log\u00edstica suele emplearse en tareas de clasificaci\u00f3n, ya que puede generar una salida que corresponde a la probabilidad de pertenecer a una clase espec\u00edfica (por ejemplo, un 20% de probabilidad de ser spam).</p>"},{"location":"ia/tipos_aa/supervision.html#aprendizaje-no-supervisado","title":"Aprendizaje no supervisado","text":"<p>En el aprendizaje no supervisado, como podr\u00e1s suponer, los datos de entrenamiento no est\u00e1n etiquetados. El sistema intenta aprender sin profesor.</p> <p></p> <p>Supongamos que disponemos de una gran cantidad de datos sobre los visitantes de nuestro blog. En este escenario, podemos aplicar un algoritmo de agrupamiento con el fin de detectar grupos de visitantes que tengan caracter\u00edsticas similares. No es necesario proporcionar al algoritmo informaci\u00f3n sobre a qu\u00e9 grupo pertenece cada visitante, ya que el algoritmo descubrir\u00e1 estas conexiones por s\u00ed mismo. Por ejemplo, podr\u00eda identificar que el 40% de los visitantes son adolescentes amantes de los c\u00f3mics que suelen leer el blog despu\u00e9s de la escuela, mientras que el 20% son adultos aficionados a la ciencia ficci\u00f3n y visitan el blog durante los fines de semana. Utilizando un algoritmo de agrupamiento jer\u00e1rquico, tambi\u00e9n podr\u00eda subdividir estos grupos en subgrupos m\u00e1s peque\u00f1os. Esta informaci\u00f3n resulta \u00fatil para adaptar nuestras publicaciones a cada grupo de visitantes.</p> <p></p> <p>Los algoritmos de visualizaci\u00f3n son otro ejemplo de aprendizaje no supervisado. Al proporcionarles datos complejos y sin etiquetas, estos algoritmos generan representaciones 2D o 3D de los datos que se pueden visualizar f\u00e1cilmente. Su objetivo principal es preservar la estructura de los datos tanto como sea posible, evitando que los grupos separados en el espacio de entrada se superpongan en la visualizaci\u00f3n. Esto nos permite comprender c\u00f3mo se organizan los datos y, en ocasiones, identificar patrones que no hab\u00edamos percibido.</p> <p></p> <p>Una tarea relacionada es la reducci\u00f3n de la dimensionalidad, que busca simplificar los datos sin perder informaci\u00f3n esencial. Esto se logra fusionando caracter\u00edsticas correlacionadas en una sola. Por ejemplo, el algoritmo de reducci\u00f3n de la dimensionalidad podr\u00eda combinar el kilometraje y la edad de un autom\u00f3vil en una sola caracter\u00edstica que represente el desgaste del veh\u00edculo. A esto se le llama \"extracci\u00f3n de caracter\u00edsticas\".</p> <p>Otra tarea importante en el aprendizaje no supervisado es la detecci\u00f3n de anomal\u00edas. Esto implica identificar eventos inusuales, como transacciones sospechosas en tarjetas de cr\u00e9dito para prevenir el fraude, detectar defectos en productos de fabricaci\u00f3n o eliminar autom\u00e1ticamente valores at\u00edpicos de un conjunto de datos antes de utilizarlos en otros algoritmos de aprendizaje. Durante el entrenamiento, se presentan principalmente instancias normales al sistema, permiti\u00e9ndole aprender a reconocerlas. Luego, cuando se le presenta una nueva instancia, puede determinar si es una instancia normal o si es probable que sea una anomal\u00eda. Una tarea relacionada es la detecci\u00f3n de novedades, que busca identificar instancias nuevas que son significativamente diferentes de las del conjunto de entrenamiento. Para lograrlo, el conjunto de entrenamiento debe estar \"limpio\", es decir, libre de instancias que se consideren novedades.</p> <p></p> <p>Por \u00faltimo, otra tarea com\u00fan en el aprendizaje no supervisado es el aprendizaje de reglas de asociaci\u00f3n. Aqu\u00ed, el objetivo es explorar grandes vol\u00famenes de datos y descubrir relaciones interesantes entre los atributos. Por ejemplo, si gestionamos un supermercado, aplicar un algoritmo de reglas de asociaci\u00f3n a los registros de ventas podr\u00eda revelar que las personas que compran salsa barbacoa y patatas fritas suelen tambi\u00e9n adquirir bistecs. Esta informaci\u00f3n nos ayudar\u00eda a colocar estos productos cerca uno del otro en la tienda.</p>"},{"location":"ia/tipos_aa/supervision.html#aprendizaje-semisupervisado","title":"Aprendizaje semisupervisado","text":"<p>Dado que etiquetar datos suele ser una tarea laboriosa y costosa, a menudo nos encontramos con un conjunto de datos que contiene muchas instancias sin etiquetar y solo algunas que est\u00e1n etiquetadas. En este escenario, se emplea lo que se conoce como aprendizaje semisupervisado.</p> <p></p> <p>Un ejemplo destacado de esto lo encontramos en algunos servicios de almacenamiento de fotos, como Google Fotos. Cuando subimos nuestras fotos familiares a este servicio, se lleva a cabo autom\u00e1ticamente el reconocimiento de personas. El sistema identifica que una persona (A) aparece en las fotos 1, 5 y 11, mientras que otra persona (B) aparece en las fotos 2, 5 y 7. Esta es la parte no supervisada del algoritmo, que se encarga del agrupamiento. Lo \u00fanico que necesitamos hacer es proporcionar etiquetas para identificar a esas personas. Basta con asignar una etiqueta a cada individuo, y el sistema ser\u00e1 capaz de etiquetar a todos en todas las fotos, lo que resulta muy conveniente para realizar b\u00fasquedas de im\u00e1genes.</p> <p>La mayor\u00eda de los algoritmos de aprendizaje semisupervisado son combinaciones de t\u00e9cnicas no supervisadas y supervisadas. Por ejemplo, se puede emplear un algoritmo de agrupamiento para agrupar instancias similares y, posteriormente, asignar a cada instancia no etiquetada la etiqueta m\u00e1s com\u00fan de su grupo. Una vez que se ha etiquetado todo el conjunto de datos, es posible utilizar cualquier algoritmo de aprendizaje supervisado.</p>"},{"location":"ia/tipos_aa/supervision.html#aprendizaje-por-refuerzo","title":"Aprendizaje por refuerzo","text":"<p>El aprendizaje por refuerzo representa un enfoque completamente distinto. En este contexto, el sistema de aprendizaje, conocido como \"agente\", tiene la capacidad de observar su entorno, tomar decisiones y llevar a cabo acciones, y a cambio recibe \"recompensas\" (o, en algunos casos, castigos en forma de recompensas negativas). El agente debe aprender de manera aut\u00f3noma cu\u00e1l es la estrategia \u00f3ptima, conocida como \"pol\u00edtica\", que le permitir\u00e1 obtener la m\u00e1xima recompensa a lo largo del tiempo. La pol\u00edtica define qu\u00e9 acci\u00f3n debe seleccionar el agente cuando se encuentra en una situaci\u00f3n particular.</p> <p></p> <p>Un ejemplo destacado de esto es la implementaci\u00f3n del aprendizaje por refuerzo en muchos robots que buscan aprender a caminar. El programa AlphaGo de DeepMind tambi\u00e9n representa un excelente ejemplo de aprendizaje por refuerzo. Este programa salt\u00f3 a la fama en mayo de 2017 al derrotar a Ke Jie, quien en ese momento era el n\u00famero uno del mundo en el juego de go. AlphaGo desarroll\u00f3 su pol\u00edtica ganadora al analizar millones de partidas y luego jugar numerosas partidas contra s\u00ed mismo. Es importante se\u00f1alar que durante las partidas contra el campe\u00f3n, el aprendizaje estaba desactivado; AlphaGo simplemente aplicaba la pol\u00edtica que hab\u00eda aprendido. Como veremos m\u00e1s adelante, este enfoque se conoce como aprendizaje offline.</p>"},{"location":"mlops/ciclo.html","title":"Ciclo de vida de MLOps","text":"<p>El ciclo de vida del aprendizaje autom\u00e1tico es uno de los conceptos fundamentales en MLOps. Consta de tres fases amplias: dise\u00f1o, desarrollo e implementaci\u00f3n. Este es un proceso iterativo y c\u00edclico en el que no es raro ir y venir entre fases. Es importante dedicar tiempo a cada fase, ya que todas desempe\u00f1an un papel importante en el ciclo de vida completo. Durante cada fase, es importante evaluar constantemente con las partes interesadas si el proyecto de aprendizaje autom\u00e1tico debe continuar. Podr\u00eda ser que descubramos durante la fase de dise\u00f1o que solo tenemos datos limitados o que solo podemos aplicar el problema a un grupo peque\u00f1o. Esto reduce el valor a\u00f1adido y, por tanto, requiere una evaluaci\u00f3n adicional por parte de las partes interesadas.</p> <p>La siguiente imagen muestra las tareas que se realizan en cada una de las fases que componen el ciclo de vida MLOps. </p> Fases de MLOps"},{"location":"mlops/desarrollo.html","title":"Fase de desarrollo","text":"<p>En la fase de desarrollo, nos centramos en desarrollar el modelo de aprendizaje autom\u00e1tico. Hacemos esto experimentando con una combinaci\u00f3n de datos, algoritmos e hiperpar\u00e1metros de acuerdo con el dise\u00f1o de implementaci\u00f3n. Durante el experimento, entrenamos y evaluamos uno o m\u00e1s modelos para encontrar el m\u00e1s adecuado. El objetivo de la fase de desarrollo es terminar con el modelo de aprendizaje autom\u00e1tico m\u00e1s adecuado y listo para su implementaci\u00f3n.</p>"},{"location":"mlops/desarrollo.html#ingenieria-de-caracteristicas","title":"Ingenier\u00eda de caracter\u00edsticas","text":"<p>La ingenier\u00eda de caracter\u00edsticas es el proceso de seleccionar, manipular y transformar datos sin procesar en caracter\u00edsticas. Una caracter\u00edstica es una variable, como una columna de una tabla. La forma en que creamos caracter\u00edsticas a partir de los datos es una parte importante del desarrollo del aprendizaje autom\u00e1tico. Podemos usar las caracter\u00edsticas tal como aparecen en los datos sin procesar, pero tambi\u00e9n podemos crear las nuestras propias. Por ejemplo, a partir de las caracter\u00edsticas n\u00famero de pedidos y total de gasto, para un cliente dado, podr\u00edamos obtener una nueva caracter\u00edstica que fuese su media de gasto.</p> <p>Un punto importante en la ingenier\u00eda de caracter\u00edsticas es cu\u00e1ndo continuar con este proceso o cu\u00e1ndo detenerlo. Realizar una ingenier\u00eda de caracter\u00edsticas integral puede producir un modelo muy preciso o lograr m\u00e1s estabilidad. Sin embargo, realizar una ingenier\u00eda integral de caracter\u00edsticas tambi\u00e9n tiene un coste, lo que puede afectar el \u00e9xito de nuestro proyecto de aprendizaje autom\u00e1tico. M\u00e1s caracter\u00edsticas pueden ser m\u00e1s costosas, ya que esto puede requerir costosos pasos de preprocesamiento. M\u00e1s caracter\u00edsticas tambi\u00e9n requieren m\u00e1s mantenimiento. Y, por \u00faltimo, m\u00e1s funccaracter\u00edsticas tambi\u00e9n pueden generar ruido o ingenier\u00eda excesiva.</p>"},{"location":"mlops/desarrollo.html#almacen-de-caracteristicas","title":"Almac\u00e9n de caracter\u00edsticas","text":"<p>Un almac\u00e9n de caracter\u00edsticas (feature store) es un sistema centralizado donde se pueden administrar las caracter\u00edsticas. Al utilizar un almac\u00e9n de caracter\u00edsticas, un cient\u00edfico de datos puede encontrar las caracter\u00edsticas adecuadas para su proyecto, definir nuevas caracter\u00edsticas y utilizarlas para entrenar el modelo. Tambi\u00e9n es el lugar donde se pueden monitorear las caracter\u00edsticas. Al mismo tiempo, al utilizar un almac\u00e9n de caracter\u00edsticas, nos aseguramos de que las caracter\u00edsticas est\u00e9n listas para usarse como entrada para el modelo de aprendizaje autom\u00e1tico en producci\u00f3n cuando lleguen nuevas muestras.</p> Almac\u00e9n de caracter\u00edsticas <p>No es obligatorio utilizar una tienda de caracter\u00edsticas al desarrollar un modelo de aprendizaje autom\u00e1tico. En algunos casos, puede resultar redundante utilizar una tienda de caracter\u00edsticas. Los factores a considerar cuando se decide utilizar una tienda de caracter\u00edsticas son el coste computacional de las caracter\u00edsticas. A veces, las caracter\u00edsticas estar\u00e1n listas como entrada para el modelo de aprendizaje autom\u00e1tico tal como est\u00e1n. El uso de una tienda de caracter\u00edsticas tambi\u00e9n depende de la cantidad de proyectos que tengamos. Las respuestas a estas preguntas determinar\u00e1n si el desarrollo actual del aprendizaje autom\u00e1tico se beneficia de una tienda de caracter\u00edsticas o no.</p>"},{"location":"mlops/desarrollo.html#seguimiento-de-experimentos","title":"Seguimiento de experimentos","text":"<p>Parte del desarrollo del modelo de aprendizaje autom\u00e1tico consiste en realizar experimentos de aprendizaje autom\u00e1tico. En un experimento de aprendizaje autom\u00e1tico, entrenamos y evaluamos m\u00faltiples modelos de aprendizaje autom\u00e1tico para encontrar el mejor. Como en cualquier experimento, probamos diferentes configuraciones para ver cu\u00e1l funciona mejor.</p> <p>Durante los experimentos de aprendizaje autom\u00e1tico, podemos configurar diferentes modelos de aprendizaje autom\u00e1tico, por ejemplo, regresi\u00f3n lineal o redes neuronales profundas. Podemos alterar los hiperpar\u00e1metros del modelo, como el n\u00famero de capas en una red neuronal. Podr\u00edamos utilizar diferentes versiones de los datos y diferentes scripts para ejecutar el experimento. Tambi\u00e9n podemos usar diferentes archivos de configuraci\u00f3n de entorno por experimento, como qu\u00e9 versi\u00f3n de Python o R se usa y qu\u00e9 bibliotecas. Al alterar cada uno de estos factores durante los experimentos, la cantidad de configuraciones diferentes puede volverse enorme. Cada experimento tambi\u00e9n tiene un resultado diferente. Por eso es una buena idea realizar un seguimiento de las configuraciones y los resultados de cada experimento.</p> <p>Adem\u00e1s de rastrear todas las diferentes configuraciones de experimentos, el seguimiento de experimentos puede ayudar a comparar y evaluar experimentos, reproducir resultados de experimentos anteriores, colaborar con desarrolladores y partes interesadas e informar sobre los resultados a las partes interesadas.</p> <p>Dependiendo de la madurez de nuestro desarrollo de aprendizaje autom\u00e1tico, existen diferentes opciones para realizar un seguimiento de los experimentos. Podr\u00edamos empezar utilizando una hoja de c\u00e1lculo en Excel, donde anotamos los detalles de cada experimento en cada fila. Si hacemos muchos experimentos, esto requerir\u00e1 mucho trabajo manual. Tambi\u00e9n podr\u00edamos crear nuestra propia plataforma de experimentos que rastree autom\u00e1ticamente el experimento durante el entrenamiento del modelo. Tener nuestra propia plataforma nos permite crear una soluci\u00f3n personalizada para nuestro proceso espec\u00edfico. Sin embargo, esto puede costar tiempo y esfuerzo. Esto se puede resolver mediante el uso de herramientas modernas de seguimiento de experimentos, ya que est\u00e1n dise\u00f1adas para la mayor\u00eda de los casos de uso de seguimiento de experimentos. El coste econ\u00f3mico de utilizar estas herramientas puede puede ser elevado. </p>"},{"location":"mlops/desarrollo.html#entrenamiento-y-evaluacion-de-modelos","title":"Entrenamiento y evaluaci\u00f3n de modelos","text":"<p>Durante la fase de desarrollo, los cient\u00edficos de datos utilizaron datos de entrenamiento para desarrollar un modelo de aprendizaje autom\u00e1tico.</p> <p>El desarrollo se lleva a cabo en el entorno de desarrollo, que suele ser el ordenador local de un cient\u00edfico de datos o un ordenador virtual que se puede controlar de forma remota, por ejemplo, en la nube.</p>"},{"location":"mlops/despliegue.html","title":"Fase de despliegue","text":"<p>En la fase de despliegue, integramos el modelo de aprendizaje autom\u00e1tico que desarrollamos anteriormente en el proceso comercial. Esto podr\u00eda implicar la creaci\u00f3n de un microservicio a partir del modelo de aprendizaje autom\u00e1tico. Un microservicio es una peque\u00f1a aplicaci\u00f3n que incluye el modelo de aprendizaje autom\u00e1tico de modo que podamos integrarlo f\u00e1cilmente en el proceso de negocio. Tambi\u00e9n pretendemos establecer un seguimiento del modelo de aprendizaje autom\u00e1tico. Podemos configurar alertas cuando encontremos una desviaci\u00f3n de datos o cuando nuestro modelo ya no genere una predicci\u00f3n. La deriva de datos ocurre cuando nuestros datos cambian, lo que afecta el modelo de aprendizaje autom\u00e1tico.</p>"},{"location":"mlops/despliegue.html#entornos-de-produccion","title":"Entornos de producci\u00f3n","text":"<p>Una vez que se desarrolla el modelo de aprendizaje autom\u00e1tico, debemos trasladarlo al entorno de producci\u00f3n. En el entorno de producci\u00f3n, el modelo de aprendizaje autom\u00e1tico har\u00e1 predicciones basadas en datos entrantes reales. Una vez implementado, el modelo est\u00e1 activo y crear\u00e1 un impacto empresarial real.</p> <p>Sin embargo, implementar un modelo en el entorno de producci\u00f3n no es tan sencillo porque est\u00e1n configurados en diferentes entornos de ejecuci\u00f3n respecto a los utilizados en la fase de desarrollo. En un entorno de ejecuci\u00f3n de desarrollo, podemos usar diferentes versiones de Python y de ciertas librer\u00edas. Esto puede causar problemas ya que es posible que el mismo c\u00f3digo no funcione en diferentes entornos de ejecuci\u00f3n o produzca resultados diferentes.</p> <p>Para mitigar el hecho de tener diferentes entornos, podemos utilizar m\u00e1quinas separadas pero configuradas de forma id\u00e9ntica. Esto es similar a utilizar una computadora normal, con su hardware f\u00edsico, el sistema operativo, las librer\u00edas y la aplicaci\u00f3n. Las librer\u00edas y la aplicaci\u00f3n contienen el entorno de producci\u00f3n y el modelo de aprendizaje autom\u00e1tico. Esta es una soluci\u00f3n sencilla, pero dif\u00edcil de mantener y no escalable. Con cada actualizaci\u00f3n, tenemos que actualizar toda la m\u00e1quina.</p> <p>Tambi\u00e9n podemos usar una o m\u00e1s m\u00e1quinas virtuales en una m\u00e1quina separada. Cada m\u00e1quina virtual es como una versi\u00f3n virtual de una computadora f\u00edsica normal con un sistema operativo, librer\u00edas y la aplicaci\u00f3n. Una computadora que ejecuta m\u00e1quinas virtuales tiene un hipervisor. Esto ayuda a distribuir los recursos, el hardware de la computadora, entre diferentes m\u00e1quinas virtuales. Esto es m\u00e1s f\u00e1cil de mantener pero requiere muchos recursos, porque necesitamos una computadora virtual para cada aplicaci\u00f3n.</p> <p>Por \u00faltimo, podr\u00edamos usar contenedores. Esto nos permite ejecutar m\u00faltiples aplicaciones en una m\u00e1quina. Los contenedores utilizan menos recursos que una m\u00e1quina virtual y son m\u00e1s port\u00e1tiles que las aplicaciones en una m\u00e1quina virtual. Pueden verse como una versi\u00f3n m\u00e1s ligera de una m\u00e1quina virtual. La implementaci\u00f3n del modelo de aprendizaje autom\u00e1tico como contenedor es actualmente el est\u00e1ndar para MLOps. </p> Entornos de producci\u00f3n <p>El uso de contenedores proporciona numerosos beneficios. En primer lugar, son m\u00e1s f\u00e1ciles de mantener. En segundo lugar, los contenedores son muy port\u00e1tiles, ya que s\u00f3lo tenemos que construirlos una vez y luego podemos ejecutarlos en cualquier lugar. Por \u00faltimo, los contenedores se inician r\u00e1pidamente, ya que solo contienen la aplicaci\u00f3n requerida y no un hipervisor o un sistema operativo virtualizado, como necesitar\u00edamos en una m\u00e1quina virtual o separada. Sin embargo, estos beneficios no significan que cada aplicaci\u00f3n deba implementarse como un contenedor. Si la aplicaci\u00f3n ha funcionado bien en una m\u00e1quina virtual y no sufre problemas de diferentes entornos, es posible no utilizar contenedores.</p>"},{"location":"mlops/despliegue.html#arquitectura-de-microservicios","title":"Arquitectura de microservicios","text":"<p>Una vez que nos hayamos ocupado de los diferentes entornos de producci\u00f3n, debemos pensar en c\u00f3mo implementar el modelo de aprendizaje autom\u00e1tico. Esto tambi\u00e9n implica que debemos pensar en c\u00f3mo configuramos la arquitectura.</p> <p>Imaginemos que tenemos una tienda web con un servicio de pago, un servicio para el carrito de compras y un servicio para el inventario. Podemos ejecutar cada servicio en el mismo ordenador. En el desarrollo de software tradicional, las aplicaciones a menudo se creaban en una arquitectura monol\u00edtica. Esto significa que despliega como una \u00fanica aplicaci\u00f3n que incluye todos los servicios.</p> <p>Una aproximaci\u00f3n diferente es utilizar una arquitectura de microservicios. La arquitectura de microservicios es, a diferencia de la arquitectura monol\u00edtica, una colecci\u00f3n de servicios m\u00e1s peque\u00f1os que se pueden implementar de forma independiente.</p> <p>Si una aplicaci\u00f3n falla en una arquitectura de microservicios, solo falla el servicio por separado, mientras que en una arquitectura monol\u00edtica, fallar\u00e1 toda la aplicaci\u00f3n. Una aplicaci\u00f3n monol\u00edtica puede volverse compleja ya que todos los servicios est\u00e1n entrelazados y no son independientes. Esto tambi\u00e9n hace que sea m\u00e1s dif\u00edcil escalar. El uso de una arquitectura de microservicios depende de la aplicaci\u00f3n. Si nuestra aplicaci\u00f3n es muy peque\u00f1a, tener un microservicio separado para cada parte puede resultar costoso porque cada servicio requiere potencia de c\u00e1lculo y debe mantenerse de forma independiente.</p> Arquitectura mol\u00edtica vs Arquitectura de microservicios <p>Una pr\u00e1ctica com\u00fan es implementar el modelo de aprendizaje autom\u00e1tico como un microservicio. Esto nos permite utilizar el modelo de aprendizaje autom\u00e1tico para hacer predicciones basadas en datos nuevos e invisibles. Este proceso tambi\u00e9n se llama inferencia. Es el proceso en el que enviamos nuevos datos de entrada, por ejemplo, los datos de entrada de un cliente, para los cuales el modelo de aprendizaje autom\u00e1tico inferir\u00e1 un resultado. En este caso, el resultado es una predicci\u00f3n que contiene la probabilidad de que un cliente abandone.</p> <p>Para proporcionar comunicaci\u00f3n entre microservicios, se utiliza una interfaz de programaci\u00f3n de aplicaciones (o API). Una API es un conjunto de combinaciones de entrada y salida predefinidas que permite que diferentes servicios se comuniquen.</p> Inferencia <p>Una vez que el modelo se ha implementado como un microservicio y la API nos permite inferir el modelo, se requiere un \u00faltimo paso. El \u00faltimo paso es integrar el modelo dentro del proceso de negocio. Esto es diferente para cada negocio, pero la mayor\u00eda de las veces implica conectar la API con el sistema que ya est\u00e1 implementado. Antes de utilizar el modelo de aprendizaje autom\u00e1tico en producci\u00f3n, es una pr\u00e1ctica com\u00fan probar primero el modelo con una muestra de los datos para asegurarnos de que todo funcione como se esperaba.</p>"},{"location":"mlops/despliegue.html#cicd-pipeline","title":"CI/CD pipeline","text":"<p>El uso de procesos de integraci\u00f3n continua y desarrollo continuo (o CI/CD) es un concepto importante dentro del desarrollo de software. CI/CD se origin\u00f3 en DevOps y se centra en automatizar la implementaci\u00f3n de c\u00f3digo. Es una serie de pasos para desarrollar, probar e implementar el c\u00f3digo. Al utilizar una pipeline CI/CD, los desarrolladores de software pueden realizar f\u00e1cilmente cambios incrementales y luego impulsar estos cambios al entorno de producci\u00f3n. Estos mismos principios se pueden aplicar al desarrollo e implementaci\u00f3n de c\u00f3digo para modelos de aprendizaje autom\u00e1tico.</p> <p>La integraci\u00f3n continua es la pr\u00e1ctica en la que los cambios de c\u00f3digo se integran continuamente de forma r\u00e1pida y frecuente. Cada cambio se prueba autom\u00e1ticamente cuando se confirman y fusionan. De esta manera, podemos identificar errores y fallos f\u00e1cilmente y asegurarnos de que muchos desarrolladores puedan trabajar juntos en el mismo c\u00f3digo.</p> <p>El desarrollo continuo funciona junto con la integraci\u00f3n continua al automatizar la publicaci\u00f3n del c\u00f3digo que se valid\u00f3 durante el proceso de integraci\u00f3n continua. El objetivo de la pr\u00e1ctica del desarrollo continuo es tener siempre c\u00f3digo listo para producci\u00f3n.</p> <p>Configurar una pipeline de CI/CD puede resultar tedioso al principio, pero puede acelerar enormemente el proceso de implementaci\u00f3n.</p> CI/CD pipeline"},{"location":"mlops/despliegue.html#estrategias-de-despliegue","title":"Estrategias de despliegue","text":"<p>Una vez que un modelo de aprendizaje autom\u00e1tico est\u00e1 listo para implementarse, podemos elegir diferentes estrategias de despliegue. Cada estrategia tiene una forma diferente de reemplazar el antiguo modelo de aprendizaje autom\u00e1tico por el nuevo modelo de aprendizaje autom\u00e1tico. Analizaremos tres estrategias de despliegue: implementaci\u00f3n b\u00e1sica, paralela y canary.</p> <p>En una estrategia de despliegue b\u00e1sico (basic deployment), simplemente reemplazamos el modelo antiguo con el nuevo modelo en producci\u00f3n. Todos los datos de entrada nuevos se enviar\u00e1n al nuevo modelo en lugar del modelo anterior.</p> <p>En el despliegue en paralelo (shadow deployment), enviamos nuevos datos tanto al modelo nuevo como al modelo anterior. Todav\u00eda utilizamos el modelo antiguo en producci\u00f3n. Se probar\u00e1 el resultado de ambos modelos para garantizar que el nuevo modelo funcione como se espera.</p> <p>Al utilizar el despliegue canary (canary deployment), utilizamos el nuevo modelo en producci\u00f3n, pero solo para una peque\u00f1a parte de los nuevos datos entrantes. De esta manera, utilizamos el nuevo modelo de inmediato, pero en caso de que falle, solo un peque\u00f1o n\u00famero de usuarios se ver\u00e1 afectado.</p> <p>La implementaci\u00f3n b\u00e1sica es la m\u00e1s f\u00e1cil de implementar y utiliza la menor cantidad de recursos porque el nuevo modelo reemplaza completamente al anterior. Esto conlleva un alto riesgo en caso de que el modelo no funcione como se esperaba. La implementaci\u00f3n paralela es similar en t\u00e9rminos de implementaci\u00f3n, pero utiliza m\u00e1s recursos ya que ejecutamos completamente ambos modelos en lugar de reemplazar uno por el otro. No hay riesgo cuando el modelo no funciona como se esperaba. La implementaci\u00f3n canary es un poco m\u00e1s dif\u00edcil de implementar pero utiliza menos recursos que tener dos modelos completamente implementados. Sin embargo, el riesgo es ligeramente mayor cuando el nuevo modelo no funciona como se esperaba.</p> Estrategias de despliegue"},{"location":"mlops/despliegue.html#monitorizacion-y-reentreno","title":"Monitorizaci\u00f3n y reentreno","text":"<p>La monitorizaci\u00f3n y el reentrenamiento de los modelos de aprendizaje autom\u00e1tico es la \u00faltima parte de la fase de despliegue.</p>"},{"location":"mlops/despliegue.html#monitorizacion-del-modelo","title":"Monitorizaci\u00f3n del modelo","text":"<p>Podemos monitorizar el modelo observando los datos de entrada y la salida del modelo, sus predicciones. A esto se le llama monitorizaci\u00f3n estad\u00edstica. Por ejemplo, podr\u00edamos monitorizar la probabilidad prevista de que un cliente se de de baja de nuestro servicio.</p> <p>Tambi\u00e9n podemos analizar m\u00e9tricas m\u00e1s t\u00e9cnicas del modelo. A esto se le llama monitorizaci\u00f3n computacional. Podr\u00eda ser la cantidad de solicitudes entrantes que se realizan, el uso de red o la cantidad de recursos que utiliza un servidor para mantener el modelo en ejecuci\u00f3n.</p> <p>Posteriormente, descubriremos si ese cliente realmente se ha dado de baja de nuestro servicio. De esta manera podemos averiguar si el modelo funciona como se esperaba o si la calidad del modelo se deterior\u00f3 con el tiempo. Este ciclo en el que comparamos el resultado del modelo con la verdad fundamental se llama ciclo de retroalimentaci\u00f3n. El circuito de retroalimentaci\u00f3n es una parte crucial para mejorar el modelo de aprendizaje autom\u00e1tico. Utilizando el circuito de retroalimentaci\u00f3n, podemos descubrir cu\u00e1ndo y por qu\u00e9 el modelo estaba equivocado. Podr\u00edamos, por ejemplo, ver que el modelo hace una predicci\u00f3n err\u00f3nea para grupos de clientes concretos.</p>"},{"location":"mlops/despliegue.html#reentreno-del-modelo","title":"Reentreno del modelo","text":"<p>Algo inherente a los datos es que estos cambian con el tiempo. Es un hecho que el mundo est\u00e1 cambiando y, dado que nuestro modelo de aprendizaje autom\u00e1tico depende de los datos, estos cambios tambi\u00e9n afectan el modelo. Esta es tambi\u00e9n la raz\u00f3n por la que un modelo podr\u00eda necesitar reentrenamiento. Con el reentrenamiento utilizamos nuevos datos para desarrollar una nueva versi\u00f3n del modelo de aprendizaje autom\u00e1tico, de modo que aprenda y se ajuste a nuevos patrones.</p> <p>La frecuencia con la que se debe volver a entrenar depende de varios factores. El primero es el entorno empresarial. Un entorno empresarial puede estar m\u00e1s sujeto a cambios que otros. En segundo lugar, la frecuencia con la que se debe volver a reentrenar tambi\u00e9n depende del coste de este. Entrenar un modelo requiere recursos. Dependiendo de la complejidad del modelo, el reentreno requiere m\u00e1s recursos y, por tanto, m\u00e1s dinero. Por \u00faltimo, los requisitos comerciales influyen en la frecuencia con la que se vuelve a entrenar el modelo. Si se requiere que el modelo tenga siempre una precisi\u00f3n superior al 90% y un peque\u00f1o cambio en los datos hace que la precisi\u00f3n disminuya por debajo de ese umbral, ser\u00e1 necesario volver a entrenar el modelo con m\u00e1s frecuencia. La rapidez con la que disminuye la precisi\u00f3n del modelo tambi\u00e9n se denomina degradaci\u00f3n del modelo.</p> <p>Cuando volvemos a entrenar, se obtiene un nuevo modelo utilizando nuevos datos. Podr\u00edamos usar un modelo que solo use datos nuevos, de modo que haya un modelo separado entrenado con datos antiguos y un modelo entrenado con datos nuevos. Tambi\u00e9n podr\u00edamos combinar datos nuevos y antiguos para desarrollar un nuevo modelo. Esto tambi\u00e9n depender\u00e1 del dominio, el coste y el rendimiento del modelo requerido.</p> <p>Dependiendo de la madurez del aprendizaje autom\u00e1tico dentro de la empresa, tambi\u00e9n podr\u00edamos aplicar un reentrenamiento autom\u00e1tico una vez que se detecte cambios en los datos. Por ejemplo, cuando detectamos que la edad media de los clientes est\u00e1 cambiando.</p>"},{"location":"mlops/disenyo.html","title":"Fase de dise\u00f1o","text":"<p>En la fase de dise\u00f1o, nos centramos en el dise\u00f1o del proyecto de aprendizaje autom\u00e1tico. Definimos el contexto del problema y determinamos el valor a\u00f1adido del uso del aprendizaje autom\u00e1tico. Tambi\u00e9n recopilamos requisitos comerciales y establecemos m\u00e9tricas clave a trav\u00e9s de las cuales podemos rastrear el progreso del ciclo de vida del aprendizaje autom\u00e1tico. Adem\u00e1s, necesitamos recopilar datos y asegurarnos de que la calidad de los datos sea suficiente para desarrollar un modelo de aprendizaje autom\u00e1tico.</p>"},{"location":"mlops/disenyo.html#valor-anadido","title":"Valor a\u00f1adido","text":"<p>Normalmente, el ciclo de vida del aprendizaje autom\u00e1tico comienza con la determinaci\u00f3n del valor agregado de crear y ejecutar el modelo de aprendizaje autom\u00e1tico. Esto suele expresarse en t\u00e9rminos de dinero o tiempo. Determinar el valor de un modelo de aprendizaje autom\u00e1tico puede ser un poco aproximado, pero es aconsejable estimar el potencial que tiene un determinado proyecto.</p> <p>Por ejemplo, podemos tener un modelo de aprendizaje autom\u00e1tico que prediga si un cliente se va a dar de baja de nuestro servicio. Tenemos un total de 100000 clientes con una suscripci\u00f3n de 10\u20ac al mes. Si podemos predecir el 80% de los 1000 clientes que usualmente se dan de baja, podemos enviarles un descuento de la suscripci\u00f3n, el cual hace que un 50% de estos clientes finalmente no se den de baja. Esto da como resultado 1000 clientes multiplicados por ochenta por ciento multiplicados por cincuenta por ciento, es decir, 400 clientes que no abandonan. Si les damos a estos 400 clientes una suscripci\u00f3n con descuento de 8\u20ac, podemos ahorrar un total de 3200\u20ac por mes.</p>"},{"location":"mlops/disenyo.html#requirimientos-de-negocio","title":"Requirimientos de negocio","text":"<p>Aparte del valor a\u00f1adido del modelo de aprendizaje autom\u00e1tico, tambi\u00e9n debemos considerar los requisitos del negocio. Especialmente en la fase de dise\u00f1o, es fundamental pensar en el usuario final del modelo de aprendizaje autom\u00e1tico. </p> <p>Digamos que estamos construyendo un modelo de aprendizaje autom\u00e1tico que predice el n\u00famero de ventas de un producto espec\u00edfico, de modo que podamos comprar la cantidad correcta para poner en nuestra tienda. El modelo de aprendizaje autom\u00e1tico generar\u00e1 una cantidad prevista de ventas. Debemos considerar la frecuencia de las predicciones y qu\u00e9 tan r\u00e1pido las necesitamos. Tambi\u00e9n debemos evaluar la precisi\u00f3n del modelo y si sus resultados son explicables para los no expertos. </p> <p>Asimismo, la transparencia se est\u00e1 convirtiendo en un factor cada vez m\u00e1s importante en el desarrollo del aprendizaje autom\u00e1tico, ya que nos permite descubrir por qu\u00e9 el modelo hace sus predicciones, por qu\u00e9 est\u00e1 equivocado y c\u00f3mo podemos mejorar el modelo. Todos estos requisitos tienen un impacto en el algoritmo que usaremos. Dependiendo del problema que estemos tratando de resolver, tambi\u00e9n podr\u00edan existir requisitos legales y de cumplimiento para el uso del aprendizaje autom\u00e1tico. Por ejemplo, en finanzas, cuando la ley exige una explicaci\u00f3n por parte del sistema.</p> <p>Por \u00faltimo, tambi\u00e9n debemos tener en cuenta el presupuesto disponible y el tama\u00f1o del equipo.</p>"},{"location":"mlops/disenyo.html#metricas-principales","title":"M\u00e9tricas principales","text":"<p>Para ver si el ciclo de vida del aprendizaje autom\u00e1tico avanza seg\u00fan lo esperado, suele ser aconsejable realizar un seguimiento del rendimiento del modelo. Sin embargo, hay distintos roles involucrados en los procesos MLOps y, por lo tanto, cada uno tambi\u00e9n tiene su propia forma de rastrear el desempe\u00f1o. </p> <ul> <li>Un cient\u00edfico de datos analiza la precisi\u00f3n de un modelo, cu\u00e1ntas veces el algoritmo es correcto.</li> <li>Un experto en la materia est\u00e1 interesado en el impacto del modelo en el negocio, por ejemplo, en c\u00f3mo mejora su trabajo gracias al uso del aprendizaje autom\u00e1tico. Est\u00e1n interesados principalmente en m\u00e9tricas espec\u00edficas dentro de la materia.</li> <li>Un cargo empresarial estar\u00e1 m\u00e1s interesado en el valor monetario del modelo, en cu\u00e1ntos casos realmente generamos ingresos. Esto suele expresarse en dinero o tiempo. </li> </ul> <p>Para aprovechar al m\u00e1ximo el aprendizaje autom\u00e1tico, debemos alinear las diferentes m\u00e9tricas para asegurarnos de que todos est\u00e9n en la misma p\u00e1gina.</p>"},{"location":"mlops/disenyo.html#preprocesamiento-de-datos","title":"Preprocesamiento de datos","text":"<p>Durante esta fase, investigamos la calidad de los datos y c\u00f3mo extraemos los datos requeridos.</p>"},{"location":"mlops/disenyo.html#calidad-de-los-datos","title":"Calidad de los datos","text":"<p>El t\u00e9rmino calidad de los datos se refiere tanto a las caracter\u00edsticas asociadas con datos de alta calidad como a los procesos utilizados para medir o mejorar la calidad de los datos. La calidad de un modelo de aprendizaje autom\u00e1tico depende en gran medida de la calidad de los datos. Los datos son el n\u00facleo del modelo de aprendizaje autom\u00e1tico. Por lo tanto, tener una visi\u00f3n clara de la calidad de los datos es crucial para el \u00e9xito del ciclo de vida del aprendizaje autom\u00e1tico. Tener una mala calidad de los datos es perjudicial para el rendimiento del modelo de aprendizaje autom\u00e1tico. Mejorar la calidad de los datos suele ser el primer paso para mejorar el rendimiento del modelo. La calidad de los datos puede definirse en base a cuatro caracter\u00edsticas:</p> <ul> <li>Exactidud: describe el grado en que los datos son exactos o correctos para la tarea en cuesti\u00f3n.</li> <li>Completitud: trata de hasta qu\u00e9 punto los datos describen completamente el problema en cuesti\u00f3n.</li> <li>Consistencia: trata sobre si los datos tienen distintos significados dentro de un mismo sistema inform\u00e1tico.</li> <li>Disponibilidad: trata de en qu\u00e9 plazo los datos estar\u00e1n disponibles.</li> </ul>"},{"location":"mlops/disenyo.html#extraccion-y-procesamiento-de-datos","title":"Extracci\u00f3n y procesamiento de datos","text":"<p>En esta fase tambi\u00e9n analizamos c\u00f3mo extraer y procesar datos. Esto se hace mediante el uso de un canal de datos automatizado (data pipeline). Una canalizaci\u00f3n de datos suele ser una parte del ciclo de vida del aprendizaje autom\u00e1tico a trav\u00e9s del cual los datos se procesan autom\u00e1ticamente. Un tipo com\u00fan de proceso de ingesta de datos es ETL (extract, transform and load). Los datos se extraen de la fuente, se transforman al formato requerido y se cargan en alguna base de datos interna o propietaria. En un proceso ETL, tambi\u00e9n podemos incluir verificaciones automatizadas, como las expectativas que tenemos sobre ciertas columnas de datos. Por ejemplo, esperamos que la columna de temperatura siempre contenga un n\u00famero. Incluir estas comprobaciones automatizadas en un proceso de datos ayuda a acelerar la fase de desarrollo e implementaci\u00f3n del ciclo de vida, ya que los datos defectuosos o de baja calidad afectar\u00e1n el modelo de aprendizaje autom\u00e1tico.</p>"},{"location":"mlops/herramientas.html","title":"Herramientas","text":"<p>Desde la aparici\u00f3n de MLOps, se han desarrollado muchas herramientas que pueden mejorar la eficiencia y confiabilidad de los procesos de aprendizaje autom\u00e1tico. Algunas de estas herramientas son de c\u00f3digo abierto.</p> <p>Para el almac\u00e9n de caracter\u00edsticas, hay varias herramientas disponibles, como Feast y Hopsworks. Feast es una almac\u00e9n de caracter\u00edsticas de c\u00f3digo abierto. Feast es una almac\u00e9n de caracter\u00edsticas autoadministrada, lo que significa que tenemos que administrarla nosotros mismos, lo que requiere m\u00e1s trabajo pero tambi\u00e9n proporciona m\u00e1s flexibilidad en comparaci\u00f3n con otras almacenes de caracter\u00edsticas. Hopsworks tambi\u00e9n es una almac\u00e9n de caracter\u00edsticas de c\u00f3digo abierto, que forma parte de la plataforma m\u00e1s grande Hopsworks. </p> <p>Para el seguimiento de experimentos, podemos utilizar MLFlow, ClearML y Weights and Biases, entre otros. MLFlow y ClearML ofrecen herramientas para el ciclo de vida del aprendizaje autom\u00e1tico, incluido el seguimiento de experimentos. MLFlow se especializa en el desarrollo de aprendizaje autom\u00e1tico, mientras que ClearML tambi\u00e9n proporciona herramientas para implementar modelos. Weights and Biases se centra principalmente en rastrear y visualizar los resultados de los experimentos.</p> <p>Para la contenedorizaci\u00f3n, Docker es la herramienta m\u00e1s popular para contener una aplicaci\u00f3n. Kubernetes se utiliza para ejecutar la aplicaci\u00f3n en contenedores, lo que permite la implementaci\u00f3n y escalabilidad autom\u00e1ticas. Adem\u00e1s de estas herramientas de c\u00f3digo abierto, los proveedores de nube AWS, Azure y Google Cloud tambi\u00e9n ofrecen sus propias herramientas para ejecutar aplicaciones en contenedores.</p> <p>Para proporcionar CI/CD pipelines existen herramientas como Jenkins y GitLab. Jenkins es una herramienta de CI/CD de c\u00f3digo abierto, mientras que GitLab no lo es. Ambas herramientas permiten a los desarrolladores trabajar juntos en el c\u00f3digo utilizando un repositorio. Para cada proyecto, suele haber un repositorio independiente, que podemos ver como un directorio que contiene todo el c\u00f3digo del proyecto.</p> <p>Existe una amplia gama de herramientas para monitorear proyectos de aprendizaje autom\u00e1tico. Podemos distinguir herramientas que se centran en el seguimiento del modelo de aprendizaje autom\u00e1tico y herramientas que monitorean los datos. Tanto Fiddler como Great Expectations proporcionan herramientas de monitorizaci\u00f3n. Fiddler se centra en el rendimiento del modelo, por ejemplo, qu\u00e9 tan bien est\u00e1n funcionando las predicciones de nuestro modelo. Great Expectations se centra en la monitorizaci\u00f3n de datos, por ejemplo, cu\u00e1ntos datos faltan en una determinada columna.</p> <p>Tambi\u00e9n hay herramientas disponibles que proporcionan una plataforma completa del ciclo de vida del aprendizaje autom\u00e1tico. Cada proveedor de nube, AWS, Azure y Google, tiene uno. Se llaman AWS Sagemaker, Azure Machine Learning y Google Cloud AI Platform. Las herramientas que abarcan todo el ciclo de vida del aprendizaje autom\u00e1tico proporcionan herramientas para cada tarea del ciclo de vida. Esta podr\u00eda ser una herramienta para realizar exploraci\u00f3n y procesamiento de datos, pero tambi\u00e9n un almac\u00e9n de caracter\u00edsticas y una herramienta de capacitaci\u00f3n de modelos.</p> Herramientas MLOps"},{"location":"mlops/introduccion.html","title":"Introducci\u00f3n","text":"<p>Hasta ahora nos hemos centrado en el desarrollo y prueba de modelos de inteligencia artificial de manera artesanal,  sin seguir ning\u00fan tipo de metodolog\u00eda que nos ayude a planificar adecuadamente un proyecto que integre un modelo de inteligencia artifical dentro de los requerimientos de una empresa.</p> <p>El t\u00e9rmino MLOps se cre\u00f3 para dar cabida a distintas metodolog\u00edas que ayuden en este proceso.</p>"},{"location":"mlops/introduccion.html#definicion-de-mlops","title":"Definici\u00f3n de MLOps","text":"<p>MLOps es la abreviatura de Machine Learning Operations y describe el conjunto de pr\u00e1cticas para dise\u00f1ar, implementar y mantener el aprendizaje autom\u00e1tico en producci\u00f3n de forma continua, confiable y eficiente. \"En producci\u00f3n\" significa que se centra en el aprendizaje autom\u00e1tico que se utiliza en los procesos empresariales en lugar de en un modelo de aprendizaje autom\u00e1tico que solo existe en un ordenador. Tambi\u00e9n se analiza algo m\u00e1s que simplemente entrenar un modelo de aprendizaje autom\u00e1tico. MLOps se aplica a lo que llamamos el ciclo de vida del aprendizaje autom\u00e1tico, que incluye desde el dise\u00f1o y desarrollo hasta el mantenimiento del aprendizaje autom\u00e1tico en producci\u00f3n.</p> <p>MLOps se origina en el t\u00e9rmino DevOps, Development Operations. DevOps describe un conjunto de pr\u00e1cticas y herramientas que se pueden aplicar al desarrollo de software para garantizar que el software se desarrolle de forma continua, confiable y eficiente. El desarrollo de software tradicional sol\u00eda ser lento debido a la separaci\u00f3n de los equipos de Desarrollo y Operaciones. El equipo de desarrollo est\u00e1 formado por las personas que escriben el c\u00f3digo, que fueron separadas del equipo de operaciones, las personas que implementan y dan soporte al c\u00f3digo. Es por eso que DevOps es una integraci\u00f3n de ambos equipos. De manera similar a c\u00f3mo se aplica DevOps al desarrollo de software, MLOps se aplica al desarrollo de aprendizaje autom\u00e1tico.</p> <p>El uso de pr\u00e1cticas y herramientas de MLOps tiene m\u00faltiples beneficios. Puede, por ejemplo, mejorar la velocidad general de desarrollo y entrega de modelos de aprendizaje autom\u00e1tico. Los procesos tambi\u00e9n se vuelven m\u00e1s confiables y seguros gracias a MLOps. Asimismo, tiene como objetivo cerrar la brecha entre el aprendizaje autom\u00e1tico y los equipos de operaciones, lo que mejora la colaboraci\u00f3n. </p>"},{"location":"mlops/wandb.html","title":"Weight &amp; Biases","text":"<p>Es una herramienta de MLOps con la que podemos:</p> <ul> <li>Realizar el seguimiento de nuestros experimentos en tiempo real.</li> <li>Versionar conjuntos de datos y modelos.</li> <li>Ajustar hiperpar\u00e1metros de forma eficiente.</li> <li>Reproducir el entrenamiento de un modelo.</li> <li>Visualizar resultados.</li> <li>Crear informes y colaborar con otros ingenieros.</li> </ul>"},{"location":"mlops/wandb.html#artifacts","title":"Artifacts","text":"<p>Los Artifacts son los objetos que nos permiten hacer un seguimiento de los conjuntos de datos, modelos, dependencias y resultados en cada paso en nuestra pipeline. En W&amp;B, los artifacts pueden ser:</p> <ul> <li>Una entrada de una run o experimento</li> <li>Una salida de esa run o experimento</li> </ul> Artifacts <p>W&amp;B combina los artifacts con las runs para crear un Directed Acyclic Graph DAG autom\u00e1ticamente, de forma que la salida de un run puede ser la entrada de otra. La plataforma nos permite visualizar este gr\u00e1fico y ver todas las relaciones entre nuestro experimentos, datasets, etc. en nuestro proyecto.</p> DAG <p>Podemos pensar que un artifact es el equivalente a un directorio de datos. Cada vez que se modifica el contenido de este directorio autom\u00e1ticamente se crea una nueva versi\u00f3n de este artifact. De esta forma, podemos volver a una versi\u00f3n anterior si fuera necesario. El funcionamiento ser\u00eda similar a un sistema de control de versiones, como git.</p>"},{"location":"mlops/wandb.html#model-registry","title":"Model registry","text":"<p>El model registry de W&amp;B es un sistema central donde podemos guardar nuestros mejores modelos. Podemos: * Versionar modelos para una tarea, catalogar cambios y comparar los modelos * Documentar y reproducir la pipeline de entrenamiento y evaluaci\u00f3n. * Gestionar el proceso desde que el modelo pasa por el entrenamiento a staging y finalmente a producci\u00f3n.</p> <p>Un model artifact est\u00e1 compuesto por una secuencia de versiones de un modelo. Cada versi\u00f3n de un modelo es un paquete de datos y metadatos que lo describe. Un modelo registrado es una selecci\u00f3n de versiones de modelos conectados que normalmente representa todos los modelos candidatos a una tarea.</p> Model artifact Model artifact <p>Podemos acceder al modelo registrado como si de un artifact se tratara. Tambi\u00e9n hace de colecci\u00f3n donde cada versi\u00f3n de un modelo registrado es un enlace a una versi\u00f3n de un modelo que pertenece a un artifact del mismo tipo. Una versi\u00f3n de un modelo puede vincularse a cualquier n\u00famero de modelos registrados.</p> Model registry <p>La separaci\u00f3n de artifacts y modelos registrados permite producir un gran n\u00famero de artefactos durante nuestros experimentos y \u00fanicamente seleccionar los mejores modelos y vincularlos al modelo registrado. De esta manera se mejora la colaboraci\u00f3n y la gesti\u00f3n de modelos.</p>"}]}